2020/06/08 05:05:51,https://www.linkedin.com/jobs/view/1863382915/?eBP=CwEAAAFykylLmFTIjSZr158Xawx2wMnpC9pS86AE2kHqYmqk0jC0OX4inyU-jGGtfvpF4DXqxrfYK1ItBbkULqFN7MKsfFoKInxrebuknfjUv05e9aoOkJzTCWzj4e55r-9qF3GspdZidXTpeiVuPZwQ9lHdXldkmzIGcY_9J6RVaYg9dn7UIWnib6Ogfmf8Y3rYNJHKVGtdzje_2nnuQ-m0NKeKy7q1BfHheqSYZy_xKyl2QgbjUVz-aiQ0P4Ii5o6NriBtUtASIRN79cmceGCcGByB_J9ZogsElpdaY2penanJ4tfzun_tGO2axzP_6TW9bU-h_Pyzr9Xg0eLvM0-PSXAYO2oDAdEzz5K9s951MmgA1a9tAAPyn630HsTEpUeE2svWli59ouHCRyHK&recommendedFlavor=IN_NETWORK&refId=48300b58-5c25-4b14-a39c-d9cd820c7bcf&trk=flagship3_search_srp_jobs,Associate - Data Science,TD,"Toronto, CA",Posted 2 days ago,89,"['Python (Programming Language)', 'Machine Learning', 'SQL', 'Data Analysis', 'R', 'Data Science', 'Microsoft Office', 'Microsoft Excel', 'Data Visualization', 'Research']","['35 Entry level applicants', '21 Senior level applicants']","['89% Applicants', '56% Applicants in the past day']",,Full-time,"['Banking', 'Financial Services', 'Insurance']","TD Description, , Tell us your story. Don't go unnoticed. Explain why you're a winning candidate. Think ""TD"" if you crave meaningful work and embrace change like we do. We are a trusted North American leader that cares about people and inspires them to grow and move forward., , Stay current and competitive. Carve out a career for yourself. Grow with us. Here's our story: jobs.td.com, , Department Overview, The successful candidate will apply data science and analytics techniques across data engineering, statistics and machine learning for investment banking advisory business. The array of projects includes client prospecting, relationship management, pricing, investor analysis just to name a few., , Job Description, The team consists of data scientists, developers, product specialists, end-users, and data engineers. This is a unique opportunity for a motivated candidate who is passionate about investment banking and can conceptualize innovative analytical products to deliver results. The candidate will work on projects ranging from business intelligence, descriptive metrics, predictive models and automated decision making. The goal is to add immense value to our clients and franchise using TD Securities' variety of proprietary data assets combined with leading edge machine learning and cloud service partnerships. This role will require high collaboration and engagement with multiple groups within TD Bank., , As a data scientist, you are a hybrid thinker with the following skillset:, Deep understanding of capital markets and/or strong motivation to gain this knowledge and develop deep subject matter expertise in this area., Fluency in using tools and methods of exploratory data analysis, visualization and modeling in Python e.g., pandas, scipy, sklearn, dash plotly, etc, Strong Python (in an object-oriented way) and SQL programming skills. Prior software development skills / experience is preferred., Engage investment bankers to solve real-world problems in areas such as relationship mapping, complex data aggregations, time-series predictions, classification, outlier detection, etc., Rapidly prototype early-stage solutions (MVP) and be objective on its efficacy to end-state., Organize and deliver a comprehensive project view from data collection, data wrangling to model development, visualization and training., Document assumptions and methodologies, carry out validation and testing to facilitate peer reviews and independent model validation, Think strategically by proposing new business metrics / alternative approaches or creating highly interpretive models., Partner with technology on infrastructure, SDLC and deployment processes., Partner with TD Bank's innovation lab., Familiarity with big data technologies, like Hadoop/HDFS, Impala/Hive, Spark, Scala etc., Strong practical data-analysis skills on real datasets, gained through hands-on experience through projects etc., Strong ownership mentality and entrepreneurial mind-set; able to translate business problems into analytical solutions and insights all the way from data process (assessing data needs, sourcing the data from the right sources, preprocessing it, evaluating its quality) to modelling and communicating/storytelling the outcome., Creative and innovative thinker who brings ways to answer key business questions in different ways while considering the existing ones if any., , , , Job Requirements, 1-2 years of hands-on experience developing statistics and machine learning models., Strong ability to develop and debug in Python., Knowledge or experience with Statistics and ML techniques, Strong experience/knowledge with machine learning APIs and computational packages (TensorFlow, Theano, PyTorch, Keras, Scikit-Learn, NumPy, SciPy, Pandas, statsmodels)., Experience with big-data technologies such as Hadoop, Spark, SparkML, etc., Experience with public cloud and services (AWS, Azure), Familiarity with basic data table operations (SQL, Hive, PostGres, Django, etc.), Experience in Deep Learning: DNN, CNN, RNN/LSTM, GAN or other auto encoder (AE)., A STEM undergraduate degree (preferably computer science or math) from a top tier institution bringing strong math, statistics and problem-solving skills., , Additional Information, , Inclusiveness, , At TD, we are committed to fostering an inclusive, accessible environment, where all employees and customers feel valued, respected and supported. We are dedicated to building a workforce that reflects the diversity of our customers and communities in which we live and serve. If you require an accommodation for the recruitment/interview process (including alternate formats of materials, or accessible meeting rooms or other accommodation), please let us know and we will work with you to meet your needs.","The Toronto-Dominion Bank & its subsidiaries are collectively known as TD Bank Group (TD). TD is the sixth largest bank in North America by branches & serves approximately 22 million customers in a number of locations in key financial centres around the globe. Over 85,000 TD employees represent the strongest team in banking. Delivering legendary customer experiences is who we are & is part of being the Better Bank. Visit our Careers page to learn more about TD & why TD is a great place to work."
2020/06/08 05:06:27,https://www.linkedin.com/jobs/view/1876263919/?eBP=JOB_SEARCH_ORGANIC&recommendedFlavor=COMPANY_RECRUIT&refId=48300b58-5c25-4b14-a39c-d9cd820c7bcf&trk=flagship3_search_srp_jobs,Data Scientist,Aviva Canada,"Markham, Ontario, Canada",Posted 1 week ago,952,"['Python (Programming Language)', 'SQL', 'Machine Learning', 'Data Analysis', 'R', 'Data Science', 'C++', 'Java', 'Microsoft Office', 'Microsoft Excel']","['339 Entry level applicants', '262 Senior level applicants', '21 Manager level applicants', '5 VP level applicants']","['952% Applicants', '44% Applicants in the past day']",Mid-Senior level,Full-time,['Insurance'],"Join an exciting team of actuaries, data scientists and engineers at the forefront of using data to drive decisions at every level of our organization. The insurance industry is undergoing a transformation and you get to be in the driver’s seat of this data-driven, technology revolution., You will work on impactful projects that range from predicting customer life-time values and optimizing customer journeys to incorporating novel data sources for building cutting-edge pricing algorithms. You will leverage machine-learning algorithms to automate and predict claim outcomes and find new and innovative ways to impact our customers. This team is exploring the frontiers of the insurance business such as how to harness the data from connected homes and cars to deliver new types of products to customers., , As a data-scientist, you will be part of a dynamic small team with exposure to different business partners and direct influence on future products and innovative solutions. You will propose machine-learning and statistical models for practical applications that impacts millions of customers. You will also mentor and guide your peers in novel approaches and provide peer review for their work. The team has already developed algorithms used in production systems and you will be part of the team that expands the scope of these algorithms. This is your chance to join the InsureTech revolution!, , The insurance industry has entered a period of unprecedented change, disruption and rapid technological development. Aviva recognizes that in this rapidly changing environment building a distinctive capability in Data Science is critical - demonstrating this commitment through the development of our Data Science Practice. If you are passionate about Data Science and leveraging your analytical prowess to tackle business challenges, this role could be for you. We are embracing new technology and exploring new ways of working. With our constant advancement, you will be at the forefront of a fast-evolving field. These exciting roles are at the heart of a high-performing Data Science team that is transforming Aviva in the Digital age. Here, we are creating a long-lasting legacy and optimizing every customer’s experience., , What you need to succeed, As a data-scientist, you will need the following skills and experience to succeed in the role:, , An educational background in computer-science or engineering, math, statistics, physics or related field. A minimum of MSc is required and Phd preferred., 2+ years of experience with model development and working with large datasets. This can include experience from any industry or academia (post-doc experience)., 2+ programming experience in Python or R with good grasp of software engineering standard methodologies such as code-reusability, modularity, use of repos, etc., Python/R /Dataiku, REST/XML/JSON/API ingestion, Spark/Impala/Hive, Expertise in machine learning theory and predictive modelling lifecycle, API configuration, Conformance/Alignment to IT/Enterprise Architecture standards (where applicable), Relevant experience in P&C (preferred), Shiny App development, Geo-analytics experience (ESRI/KML/KMZ layer development) with specialization in weather & environmental data ingestion, , What sets you apart, , A growth mindset with versatile skills and able to work through problems from first-principles., A portfolio of projects that demonstrate your ability to draw inferences from data. This includes participation within the broader data science community including Kaggle competitions or any personal projects with open data., A can-do teammate who is willing to roll-up the sleeves and do whatever is needed to move projects forward. That means at times you will wear different hats and be a project manager, developer, modeler and chief communicator of solutions., Amazing people skills and able to translate and communicate complex algorithms to non-technical individuals. Someone who understands that it is not enough to just have a phenomenal algorithm but meaningful to build an agreement for the solution from different partners., The best problems in the industry are yet to be articulated. We need someone who is creative, self-motivated and can lead projects independently., , Position Objectives, ,  Provide data support to Claims business inclusive of data mining, automated reporting and modelling., Transformation of complex data sets into meaningful conclusions & recommendations, Develop innovative solutions for pattern recognition using machine learning and statistical approaches, Maintenance of expanding set of data mining tools, frameworks & approaches, Communicate actionable recommendations based on insights/model results, Deliver proactive analysis on CAT exposure, historical performance and decision making using weather and geo-analytical approaches (CAT Analytics role), Driving co-ordination/delivery accountability of project and BAU delivery based on timelines & direction (Sr Data Scientist), Driving conformance/Alignment to IT/Enterprise Architecture standards (where applicable) (Sr Data Scientist)","Aviva Canada is one of the leading property and casualty insurance groups in the country, providing home, automobile, leisure/lifestyle and business insurance to 2.8 million customers. A subsidiary of UK-based Aviva plc, Aviva Canada has more than 4,000 employees focused on creating a bright and sustainable future for our customers and our communities. 

Aviva Canada invests in positive change through the Aviva Community Fund, Canada’s longest running online community funding competition. Since its inception in 2009, the Aviva Community Fund has awarded $8.5 million to over 280 charities and community groups nationwide. Aviva Canada, bringing over 300 years of good thinking and insurance solutions to Canadians from coast-to-coast. 

For more information, visit aviva.ca or Aviva Canada’s blog, Twitter, Facebook and LinkedIn pages."
2020/06/08 05:07:04,https://www.linkedin.com/jobs/view/1865134911/?eBP=CwEAAAFykylLmIzcdeAqdV27hSRPl7KSn-6cBhxM0TdRtefH900onNHDWLdeXmx5PGDyaH90U5zX4JETnILdPcNsPv67pv9oZcDQU3vXJv5tijKwySqDmDBp5dEYOPkXV1lPY3UdG8z9iWtuJulNMRFiTZBzfGwFjSD2lEPPts1pgl1fkb1k54tBS4QSBt-sx4WNI9grH9ZjDmyUXiCHPNDH8ZXkYlG-qKvQtaCgDAapj2P_D1MWp1LPwWRkw4Q9ugoIdDCke_DGO7WMrKc5soKOg4hIOo0o4QvqtACFL5pnY3MMbz_GYPrrJKhc6IFRN3tFejGmUg1uO19iTwdaGJ21If2A7y_5rg0OQz68e2ziGHhe8jVXRgc3i9167KxGlTuCf8YOmTqio6xduUb6&recommendedFlavor=SKILL_ASSESSMENTS&refId=48300b58-5c25-4b14-a39c-d9cd820c7bcf&trk=flagship3_search_srp_jobs,"Lead Data Engineer, Cloud",Ethoca,Greater Toronto Area Metropolitan Area,Posted 4 days ago,167,"['SQL', 'Python (Programming Language)', 'Java', 'Data Analysis', 'Big Data', 'Extract, Transform, Load (ETL)', 'Databases', 'Business Intelligence (BI)', 'Microsoft SQL Server', 'Microsoft Office']","['77 Senior level applicants', '46 Entry level applicants', '6 Manager level applicants', '2 Director level applicants']","['167% Applicants', '2% Applicants in the past day']",Mid-Senior level,Full-time,['Financial Services'],"At Ethoca, you’re applying for much more than a job. Where else are you going to get the opportunity to work with the most committed group of ecommerce business and technology innovators who are transforming the industry? And we’re winning the awards to prove it., We want the bold. We demand the best. And, we’re committed to giving you the opportunity to make the contribution only you can make. Ethoca is a place where risk-takers thrive, thought leaders excel and challengers make us better. , , At Ethoca, we believe that ecommerce should be about one thing: commerce. Fraud and chargebacks disrupt the payments ecosystem and prevent merchants and card issuing banks from focusing on what really matters – increasing sales and creating a great customer experience. Thankfully, our suite of services changes all that. , , The Position:, , Ethoca is seeking a Lead Data Engineer, Cloud to join our team in Toronto to drive Azure cloud enablement and explore big data solutions within our technology landscape. The role is visible and critical as part of a high performing team – it will appeal to you if you have an effective combination of domain knowledge, relevant experience and the ability to execute on the details. , , You will bring cutting edge software and full stack development skills with advanced knowledge of cloud and data lake experience while working with massive data volume. You will own this – our teams are small, agile and focused on the needs of the high growth fintech marketplace. You will be working across functional teams within Ethoca and Mastercard to deliver on the cloud strategy., We are committed in making our systems resilient and responsive yet easily maintainable on premise and on cloud., , Your Challenge:, Own the development of ETL/ELT, data movement, streaming and non-streaming data with a solid background in development of reports/dashboards, applications, services, user interfaces while maintaining and scaling existing solutions., , Existing solutions are built on data that resides in the SAP HANA data warehouse, we expect the successful candidate will always pay attention to detail: configuration, maintenance, security and reliability of data and Data Services in the different  environments as we build out a state-of-the-art analytics foundation (on premise and on cloud)., , Qualifications:, Tenured in the fields of Computer Science/Engineering or Software EngineeringBachelor's degree in Computer Science, or a related technical field including programming, Experience with cloud infrastructure management and automation (preferably Azure), Experience with software development and configuration automation is a must have, Expertise in designing, analyzing, and troubleshooting large-scale systems, Capability to debug, optimize code, and automate routine tasks, Extensive experience in Machine Learning, Hands-on experience with building data lake solutions, streaming analytics solutions and code development across environments (i.e. DevOps), , Here’s what sets you apart:, 5+ years of data warehousing/data lake development experience, Strong data modeling and data integration experience, Strong SQL and higher-level programming languages, Solid knowledge of data mining, machine learning algorithms and tools, Good understanding of data warehouse/data lake design patterns and best practices, Solid understanding of data ingestion (i.e. streaming platforms like Kafka), Strong experience with data integration tools – ETL/ELT tools (i.e. Apache NiFi, Azure Data Factory, Pentaho, Talend), Experience working:, In a Data Warehousing and BI environment with understanding of warehousing concepts, With Source Control System (SCS) is a must – preferably “Git” source control, Systematic problem-solving approach, with effective communication skills and a sense of drive, Strong understanding and working knowledge of Continuous Integration and Continuous Deployment concepts, Excellent written and verbal communication skills, Top notch problem solving and analytical skills, Plan and own deployments, migrations and upgrades to minimize service impacts with mitigation plans, Understand and tune performance across all physical and logical dimensions, Support Ethoca’s architects and analysts as they design and build effective, agile applications, Use your experience to help shape and scale the future of our development and production infrastructure, Work efficiently within a high security, PII and PCI-DSS Level 1 environment, Self-starter that explores opportunities for efficiencies and propose options to bridge gaps that exists , , Nice to have:, Scripting experience with one or more of the following:, Java and Java Script, Python, R, Experience working with analytics and data processing engines like Apache Spark/Storm, Experience with application development, Experience working with SAP HANA or Teradata, , Ideally you have experience in banking, e-commerce, credit cards or payment processing and exposure to both SaaS and premises-based architectures. In addition, you have a post-secondary degree in computer science, mathematics or a quantitative science and at least 5 plus years of increasingly responsible work experience., , Compensation, Ethoca offers a competitive compensation package, benefits and the opportunity to work with great people in a high-growth environment., , , We will only be contacting those individuals who we believe are the best potential fit with our requirements., , At Ethoca, we welcome job applications from qualified individuals without regard to race, color, religion, sex, national origin, age, disability, ancestry, family care status, veteran status, marital status, or any other lawfully protected status in every jurisdiction in which we operate.  We are committed to a diverse workforce that provides fair and equal opportunity for all employees and candidates.","At Ethoca, we believe that ecommerce should be about one thing: commerce. Fraud and chargebacks disrupt the payments ecosystem and prevent merchants and card issuing banks from focusing on what really matters – increasing sales and creating a great customer experience. Thankfully, our suite of services changes all that. 
 
Before Ethoca, merchants and issuers would identify thousands of confirmed fraudulent and disputed transactions on a daily basis. Unfortunately, they had no way to securely share this intelligence. Introduced in 2011, our flagship product – Ethoca Alerts – revolutionized the industry by closing this information gap and giving merchants an unprecedented opportunity to stop fraud and chargebacks before they happen.
 
Since that time our network has grown to include thousands of merchants and hundreds of card issuing banks across the globe – and it shows no signs of slowing down. 
 
Founded in 2005, Ethoca is headquartered in Toronto, with regional offices in Austin, London, Phoenix, Paris and Melbourne."
2020/06/08 05:07:41,https://www.linkedin.com/jobs/view/1878812296/?eBP=JOB_SEARCH_ORGANIC&recommendedFlavor=SCHOOL_RECRUIT&refId=48300b58-5c25-4b14-a39c-d9cd820c7bcf&trk=flagship3_search_srp_jobs,Data Scientist,Nielsen,"Toronto, CA",Posted 11 hours ago,156,"['Python (Programming Language)', 'SQL', 'Machine Learning', 'Data Analysis', 'R', 'Data Science', 'Microsoft Excel', 'Microsoft Office', 'Data Visualization', 'Tableau']","['50 Entry level applicants', '45 Senior level applicants', '4 Manager level applicants', '3 VP level applicants']","['156% Applicants', '51% Applicants in the past day']",,Full-time,"['Market Research', 'Management Consulting']","YOU’LL LEVERAGE DATA TO IMPACT GLOBAL BUSINESSES, , Nielsen Precima is a global strategy and analytics company that provides tailored, data-driven solutions that drive sales, boost profitability, and build customer loyalty. Leveraging our deep analytics expertise, Precima helps organizations improve their competitive position across all facets of planning and operations from assortment optimization, price optimization, promotional optimization, targeted marketing, and supplier collaboration., , This role is an integral part of the Merch Analytical Team. The successful candidate will have relevant retail industry experience and strong capabilities in statistical and mathematical modeling in advanced analytics applications. This role will have the opportunity to grow within the role and progress toward future career development objectives along a number of potential paths including a focus on deeper analyses and model development, client relationship management, and/or marketing. This role is key to ensuring that Precima delivers products/services and solutions that meet clients’ needs for tactics that increase sales and profits - and in an on-time/on budget capacity - which support client results and satisfaction and revenue retention/growth., , What You’ll Do, Create descriptive and predictive statistics, customer data tables, verification and cleaning data, producing accurate client reports and ensuring the quality of the data analysis produced. This includes the design, development, data extraction and analysis of retail client analytics., Interpret, document and present/communicate analytical results to multiple business disciplines, providing conclusions and recommendations based off customer-centric data, Work in close collaboration with internal stakeholders, as well as external partners and suppliers to leverage customer level and/or item level data., Take analytical objectives and define data requirements. Extract, clean, and transform customer and item-level data for purposes of analysis, modeling/segmentation and reporting, Hands-on data extraction and reporting off big customer database, Participate in special projects and ad-hoc as required, , , We’re Looking For People Who Have, Master’s Degree Math/Statistics, Computer Science, Economics, Industrial Engineering, Minimum of 1-2 years of directly related work or intern experience in quantitative analysis with proven results in leveraging customer/transaction to address business objectives through a structured analysis - leading to insights and recommendations., Experience within any of the following industries: retail, consumer packaged goods, banking, credit card, consulting, loyalty programs/CRM, agencies that focus on direct or analytical service. Experience in retail and/or CPG is strongly preferred., Strong in statistical techniques and the willingness to learn and champion methodologies for customer analysis, Highly proficient in SQL and Python, Ability to translate business objectives into analytical plan/framework, conducting the analysis and interpreting data to derive insights and interpret results to develop and communicate recommendations to internal teams - and then to clients., Ability to translate statistical and analytical results into clear written and verbal communication to internal/external stakeholders, Excellent ability to be part of multiple projects/initiatives of varying size and complexity, while simultaneously meeting and exceeding deadlines in a diverse environment, Strong team player and ability to work in a collaborative environment, Strong interpersonal skills including written and oral communication, , , About Nielsen Precima, , Nielsen Precima is a wholly-owned business unit of Nielsen. Nielsen Precima is a global strategy and analytics company that provides SaaS solutions for retail clients that drive sales, boost profitability, and build customer loyalty. Leveraging our deep analytics expertise, we help retail organizations improve their competitive position across assortment, price, promotional, targeted marketing, and supplier collaboration., , Nielsen is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class.","Nielsen Holdings plc (NYSE: NLSN) is a global measurement and data analytics company that provides the most complete and trusted view available of consumers and markets worldwide. Nielsen is divided into two business units. Nielsen Global Media, the arbiter of truth for media markets, provides media and advertising industries with unbiased and reliable metrics that create a shared understanding of the industry required for markets to function. Nielsen Global Connect provides consumer packaged goods manufacturers and retailers with accurate, actionable information and insights and a complete picture of the complex and changing marketplace that companies need to innovate and grow. 

Our approach marries proprietary Nielsen data with other data sources to help clients around the world understand what’s happening now, what’s happening next, and how to best act on this knowledge. An S&P 500 company, Nielsen has operations in over 100 countries, covering more than 90% of the world’s population."
2020/06/08 05:08:18,https://www.linkedin.com/jobs/view/1888280528/?alternateChannel=search&refId=48300b58-5c25-4b14-a39c-d9cd820c7bcf&trk=flagship3_search_srp_jobs,Data Governance Specialist - (Technology / Regulations/ Data Streaming / Cloud) R190023497,BMO Financial Group,"Toronto, Ontario, Canada",Posted 6 days ago,17,"['SQL', 'Data Analysis', 'Python (Programming Language)', 'Teamwork', 'Microsoft Excel', 'Data Modeling', 'Microsoft Office', 'Data Visualization', 'Business Intelligence (BI)', 'Leadership']","['5 Entry level applicants', '3 Senior level applicants', '1 Director level applicant', '1 Manager level applicant']","['17% Applicants', '0% Applicants in the past day']",Mid-Senior level,Full-time,['Financial Services'],"Thank you for your interest in BMO Financial Group. We are currently working towards providing a better candidate experience by including all of our job descriptions in both English and French. In the meantime, if this role is located in Quebec and/or New Brunswick please reference the French job description available below the English version. Otherwise please see the job description below in English as per federal language requirements., Nous vous remercions pour votre intérêt à l'égard de BMO Groupe financier. Nous travaillons actuellement à offrir une meilleure expérience aux candidats en publiant toutes nos descriptions de poste en français et en anglais. Entre-temps, si ce poste est affiché au Québec ou au Nouveau-Brunswick, veuillez consulter la description de poste en français disponible sous la version anglaise. Autrement, veuillez consulter la description de poste ci-dessous en anglais, conformément aux exigences fédérales en matière de langues., The Data Governance Specialist is accountable for the analysis, design, development, implementation and support of various data governance and data quality initiatives in support of the Lines of Business strategies., , Some Specific Functions of this Role:, , Establish, implement and manage data governance and data management standards, policies, procedures and processes for Metadata and Data Quality Management., Monitor adherence to data policies across the organization to ensure availability of high-quality data, consultative and subject matter expertise, ensuring all users of data understand policies, procedures and standards., Assesses the data quality and monitors data quality health, Interfaces with senior management and contributes towards ongoing data quality improvement initiatives, Collaborates with other technology stakeholders to ensure that the data policies, procedures, standards/processes are consistent where possible and align with enterprise standards., Participates in project and team meetings interacting and collaborating with team members and other departments as appropriate, Contributes to successful completion of project deliverables, Provides support to team members and application, Provides some support for production and non-production environments, , Knowledge and Skills:, , Minimum 5 years of experience in supporting enterprise wide data governance including measuring/monitoring data quality, recommending improvements in data, Experience and knowledge of data governance in a cross-functional environment of multiple data sources/repositories, Ability to recommend improvements in data management process and technology solutions to ensure user requirements are met., Solid understanding of SDLC and QA requirements, Possesses solid analytical skills for complex problem solving. Is able to manage multiple priorities., Self-starter, ability to adapt and quickly develop in-depth technical understanding of new/different applications., Detail oriented with strong organizational skills, Solid communication skills both written and verbal, Good understanding of emerging technologies, University degree or college diploma in Computer Science, Financial Services industry experience or related is an asset, , Technical Skills:, , Expertise in data governance and data quality experience using industry standard tools, Expertise in Event driven SOA and/or EAI applications and ability to translate business needs into technical requirements., Expert knowledge in Kafka, Confluent platforms would be desirable, Experience of data streaming using AWS Kinesis and Kafka is nice to have, Thorough experience on Cloud platforms would be a strong asset, Solid knowledge JSON and modern integration frameworks","At BMO we have a shared purpose; we put the customer at the centre of everything we do – helping people is in our DNA. For 200 years we have thought about the future—the future of our customers, our communities and our people. We help our customers and our communities by working together, innovating and pushing boundaries to bring them our very best every day. Together we’re changing the way people think about a bank. 
 As a member of the BMO team you are valued, respected and heard, and you have more ways to grow and make an impact. We strive to help you make an impact from day one – for yourself and our customers. We’ll support you with the tools and resources you need to reach new milestones, as you help our customers reach theirs. From in-depth training and coaching, to manager support and network-building opportunities, we’ll help you gain valuable experience, and broaden your skillset. 
 To find out more visit us at https://bmocareers.com. 
 To submit your application for this job, please go to: 
 https://bmo.wd3.myworkdayjobs.com/External/job/Toronto-ON-CAN/Data-Governance-Specialist----Technology---Regulations--Data-Streaming---Cloud-_R190023497-1 
 BMO is committed to an inclusive, equitable and accessible workplace. By learning from each other’s differences, we gain strength through our people and our perspectives. Accommodations are available on request for candidates taking part in all aspects of the selection process."
2020/06/08 05:08:54,https://www.linkedin.com/jobs/view/1888280528/?eBP=CwEAAAFykylLmIz5YWNEp6yrsvmyW_I6rvYUPrD4ATK96o4rNkMjqo2hNVSXMkGoZgtwKNYrovc9QY6gTNj5hLxBTXoQqawCZKjP5HDCkKB86wPHR1DuBGXp2knFSUz26NMYxKt0w9pNwtgMXDYPBRV7-4RoWqImBvpQjwn3seqFQ2aOpIIXfImx4_Wg-tOjAtasLaz1G0CsVtlQV0-C2fRGkKq4PI6Ur2P1dmLdit6kCDdjUKeR4HUx8dsQTG_Z3KKKa9KZBxlQGI8HTDRuOTe0ozbU8WG_XOn2cJXAZl7k-5M1mr-rkvRDW5RksYT8Mi02e4dO1CzIeEib3kJQOd5Y19SApTPU94DVav0TZtLnKPwdpCRa91m6p_-2yDsrLD935erDbZKGJKYbNPRl&recommendedFlavor=IN_NETWORK&refId=48300b58-5c25-4b14-a39c-d9cd820c7bcf&trk=flagship3_search_srp_jobs,Data Governance Specialist - (Technology / Regulations/ Data Streaming / Cloud) R190023497,BMO Financial Group,"Toronto, Ontario, Canada",Posted 6 days ago,17,"['SQL', 'Data Analysis', 'Python (Programming Language)', 'Teamwork', 'Microsoft Excel', 'Data Modeling', 'Microsoft Office', 'Data Visualization', 'Business Intelligence (BI)', 'Leadership']","['5 Entry level applicants', '3 Senior level applicants', '1 Director level applicant', '1 Manager level applicant']","['17% Applicants', '0% Applicants in the past day']",Mid-Senior level,Full-time,['Financial Services'],"Thank you for your interest in BMO Financial Group. We are currently working towards providing a better candidate experience by including all of our job descriptions in both English and French. In the meantime, if this role is located in Quebec and/or New Brunswick please reference the French job description available below the English version. Otherwise please see the job description below in English as per federal language requirements., Nous vous remercions pour votre intérêt à l'égard de BMO Groupe financier. Nous travaillons actuellement à offrir une meilleure expérience aux candidats en publiant toutes nos descriptions de poste en français et en anglais. Entre-temps, si ce poste est affiché au Québec ou au Nouveau-Brunswick, veuillez consulter la description de poste en français disponible sous la version anglaise. Autrement, veuillez consulter la description de poste ci-dessous en anglais, conformément aux exigences fédérales en matière de langues., The Data Governance Specialist is accountable for the analysis, design, development, implementation and support of various data governance and data quality initiatives in support of the Lines of Business strategies., , Some Specific Functions of this Role:, , Establish, implement and manage data governance and data management standards, policies, procedures and processes for Metadata and Data Quality Management., Monitor adherence to data policies across the organization to ensure availability of high-quality data, consultative and subject matter expertise, ensuring all users of data understand policies, procedures and standards., Assesses the data quality and monitors data quality health, Interfaces with senior management and contributes towards ongoing data quality improvement initiatives, Collaborates with other technology stakeholders to ensure that the data policies, procedures, standards/processes are consistent where possible and align with enterprise standards., Participates in project and team meetings interacting and collaborating with team members and other departments as appropriate, Contributes to successful completion of project deliverables, Provides support to team members and application, Provides some support for production and non-production environments, , Knowledge and Skills:, , Minimum 5 years of experience in supporting enterprise wide data governance including measuring/monitoring data quality, recommending improvements in data, Experience and knowledge of data governance in a cross-functional environment of multiple data sources/repositories, Ability to recommend improvements in data management process and technology solutions to ensure user requirements are met., Solid understanding of SDLC and QA requirements, Possesses solid analytical skills for complex problem solving. Is able to manage multiple priorities., Self-starter, ability to adapt and quickly develop in-depth technical understanding of new/different applications., Detail oriented with strong organizational skills, Solid communication skills both written and verbal, Good understanding of emerging technologies, University degree or college diploma in Computer Science, Financial Services industry experience or related is an asset, , Technical Skills:, , Expertise in data governance and data quality experience using industry standard tools, Expertise in Event driven SOA and/or EAI applications and ability to translate business needs into technical requirements., Expert knowledge in Kafka, Confluent platforms would be desirable, Experience of data streaming using AWS Kinesis and Kafka is nice to have, Thorough experience on Cloud platforms would be a strong asset, Solid knowledge JSON and modern integration frameworks","At BMO we have a shared purpose; we put the customer at the centre of everything we do – helping people is in our DNA. For 200 years we have thought about the future—the future of our customers, our communities and our people. We help our customers and our communities by working together, innovating and pushing boundaries to bring them our very best every day. Together we’re changing the way people think about a bank. 
 As a member of the BMO team you are valued, respected and heard, and you have more ways to grow and make an impact. We strive to help you make an impact from day one – for yourself and our customers. We’ll support you with the tools and resources you need to reach new milestones, as you help our customers reach theirs. From in-depth training and coaching, to manager support and network-building opportunities, we’ll help you gain valuable experience, and broaden your skillset. 
 To find out more visit us at https://bmocareers.com. 
 To submit your application for this job, please go to: 
 https://bmo.wd3.myworkdayjobs.com/External/job/Toronto-ON-CAN/Data-Governance-Specialist----Technology---Regulations--Data-Streaming---Cloud-_R190023497-1 
 BMO is committed to an inclusive, equitable and accessible workplace. By learning from each other’s differences, we gain strength through our people and our perspectives. Accommodations are available on request for candidates taking part in all aspects of the selection process."
2020/06/08 05:09:30,https://www.linkedin.com/jobs/view/1883579706/?eBP=NotAvailableFromVoyagerAPI&recommendedFlavor=IN_NETWORK&refId=48300b58-5c25-4b14-a39c-d9cd820c7bcf&trk=flagship3_search_srp_jobs,Data Analyst,Veeva Systems,"Toronto, CA",Posted 1 week ago,328,"['SQL', 'Data Analysis', 'Python (Programming Language)', 'R', 'Machine Learning', 'Teamwork', 'Microsoft Excel', 'Microsoft Office', 'Tableau', 'Data Visualization']","['82 Entry level applicants', '70 Senior level applicants', '2 Manager level applicants']","['328% Applicants', '6% Applicants in the past day']",,Full-time,"['Computer Software', 'Information Technology & Services', 'Pharmaceuticals']","At Veeva, we build enterprise cloud technology that powers the biggest names in the pharmaceutical, biotech, consumer goods, chemical & cosmetics industries. Our customers make vaccines, life-saving medicines, and life-enhancing products that make a difference in everyday lives. Our technology has transformed these industries; enabling them to get critical products and services to market faster. Our core values, Do the Right Thing, Customer Success, Employee Success, and Speed, guide us as we make our customers more efficient and effective in everything they do., , The Role, , Veeva is looking for an all-star Data Analyst to grow a global data platform for Customer Relationship Management and other applications. We’re looking for a high-energy, passionate individual with experience working with and mining data to discover trends and derive business important insights., , In this role, you will be responsible for creating standard reports as well as custom analysis, as required, based on changing business conditions within a therapeutic area or country. You will need a good understanding of the Life Sciences industry on how field sales, medical, and marketing work. You will help create and work with benchmarks to make the industry promotional and scientific exchange efforts more productive, which will impact patient treatment and outcomes. You need to be able to think Big Data with a global data set, but also Small Data and be good with details as trending can be very localized., , What You'll Do, Collaborate closely with Product Management, Data Scientists, and Data Engineers to build the data platform, Create standard reports and run reports for various stakeholders, Investigate data and propose a business rationale for behavior based on an understanding of the Life Sciences industry, Build and maintain reference data groupings such as Therapeutic Areas, indications, etc., Derive meaningful and impactful insights from the data, and communicate possibilities unearthed through data., Have a good intuition on when data cannot be taken at face value, and build context and meaning around metrics., Proactively suggest new ideas and ways of operating, Educate others and be a champion of how to use this data set, , Requirements, Excellent communication skills; written, verbal and formal presentation, BA/BS degree in Computer Science, Engineering, Math, or related technical field, 2+ years of hands-on data analysis experience, 3 years or more of experience with enterprise software, Energized by working through complex problems and love working with data, Experience with commercial aspects of the Life Sciences industry, , Nice to Have, Experience with Veeva CRM, Worked on global life science programmes, , Perks & Benefits, Conveniently located in downtown Toronto, Snacks, beverages, and weekly lunches from local restaurants, Team events and rec league sports teams, Allocations for continuous learning & development, Health & wellness programs, Weekly yoga classes, Ping pong and other games, , Veeva’s headquarters is located in the San Francisco Bay Area with offices in more than 15 countries around the world., , Veeva Systems is an equal opportunity employer. Accordingly, we are committed to fair and accessible employment practices. Veeva Systems welcomes and encourages applications from people with disabilities. Accommodations are available upon request for candidates taking part in all aspects of the selection process.","Veeva Systems Inc. is a leader in cloud-based software for the global life sciences industry. Committed to innovation, product excellence, and customer success, Veeva has more than 875 customers, ranging from the world's largest pharmaceutical companies to emerging biotechs. Veeva is headquartered in the San Francisco Bay Area, with offices in Canada, Europe, Asia, and Latin America."
2020/06/08 05:10:07,https://www.linkedin.com/jobs/view/1870005302/?eBP=JOB_SEARCH_ORGANIC&recommendedFlavor=IN_NETWORK&refId=48300b58-5c25-4b14-a39c-d9cd820c7bcf&trk=flagship3_search_srp_jobs,Data Engineer,Amazon,"Toronto, CA",Posted 2 weeks ago,,"['SQL', 'Python (Programming Language)', 'Data Analysis', 'Java', 'Machine Learning', 'Microsoft Office', 'Microsoft Excel', 'Extract, Transform, Load (ETL)', 'Microsoft SQL Server', 'Tableau']","['61 Senior level applicants', '61 Entry level applicants', '4 Manager level applicants', '1 VP level applicant']",,,Full-time,"['Computer Software', 'Information Technology & Services', 'Internet']","Description, , Amazon.com was recently voted #2 most admired company in the US, #1 most innovative, and # 1 in Customer Service. We are investing heavily in building an excellent advertising business, and are responsible for defining, and delivering a collection of self-service performance advertising products – “always-on analytics” that is fully scalable and reliable. Our products are strategically important to our leadership, finance, economists, analysts, and BI partners to drive long-term growth. We mine billions of ad impressions and millions of clicks daily and are breaking fresh ground to create world-class products. We are highly motivated, collaborative, and fun loving with an entrepreneurial spirit and bias for action. With a broad mandate to experiment and innovate, we are growing at an unprecedented rate with a seemingly endless range of new opportunities., The Advertising Analytics and Data Management team is looking for an exceptional Data Engineer who is passionate about data and the insights that large amounts of data can provide, who thinks/acts globally, and who has the ability to contribute to major novel innovations in the industry. The role will focus on working with a team of data engineers, business and tech savvy professionals to lay down scalable data architecture to ingest large amounts of structured and unstructured datasets and work with stakeholders to drive business decisions based on these datasets., , The ideal candidate will possess both a data engineering background and a strong business acumen that enables him/her to think strategically and add value to the customer experience. He/She will experience a wide range of problem solving situations, requiring extensive use of data collection and analysis techniques such as data mining and machine learning., , They Will, , The successful candidate will work with multiple global site leaders, Business Analysts, Software Developers, Database Engineers, Product Management in addition to stakeholders in sales, finance, marketing and service teams to create a coherent customer view., Develop and improve the current data architecture using AWS Redshift, AWS S3, AWS Aurora (Postgres) and Hadoop/EMR., Improve upon the data ingestion models, ETL jobs, and alarming to maintain data integrity and data availability., Stay up-to-date with advances in data persistence and big data technologies and run pilots to design the data architecture to scale with the increased data sets of advertiser experience., Partner with analysts across teams such as product management, operations, sales, finance, marketing and engineering to build and verify hypothesis to improve the business performance., Manage weekly business reports via dashboards and paper the analyses of daily, weekly, and monthly reporting of performance via Key Performance Indicators., , Basic Qualifications, 3+ years of experience as a Data Engineer or in a similar role, Experience with data modeling, data warehousing, and building ETL pipelines, Experience in SQL, Preferred Qualifications, AWS Experience, Advertising domain knowledge is a plus, Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us., , #sspajobs, , , Company - AMZN CAN Fulfillment Svcs, ULC, Job ID: A1151273","Amazon is guided by four principles: customer obsession rather than competitor focus, passion for invention, commitment to operational excellence, and long-term thinking. We are driven by the excitement of building technologies, inventing products, and providing services that change lives. We embrace new ways of doing things, make decisions quickly, and are not afraid to fail. We have the scope and capabilities of a large company, and the spirit and heart of a small one.

Together, Amazonians research and develop new technologies from Amazon Web Services to Alexa on behalf of our customers: shoppers, sellers, content creators, and developers around the world.

Our mission is to be Earth's most customer-centric company. Our actions, goals, projects, programs, and inventions begin and end with the customer top of mind.

You'll also hear us say that at Amazon, it's always ""Day 1."" What do we mean? That our approach remains the same as it was on Amazon's very first day - to make smart, fast decisions, stay nimble, invent, and focus on delighting our customers."
2020/06/08 05:11:38,https://www.linkedin.com/jobs/view/1877047321/?alternateChannel=search&refId=1249d27b-471a-4c63-abc6-102a9dd4b3d6&trk=flagship3_search_srp_jobs,Data Engineer (Toronto; Silicon Valley),Jerry.ai,"Toronto, Ontario, Canada",Posted 6 days ago,201,"['Python (Programming Language)', 'SQL', 'Data Analysis', 'Machine Learning', 'Java', 'Data Science', 'C++', 'Microsoft Office', 'Microsoft Excel', 'Tableau']","['57 Entry level applicants', '40 Senior level applicants', '2 VP level applicants', '2 Manager level applicants']","['201% Applicants', '19% Applicants in the past day']",Entry level,Full-time,['Internet'],"We’d love to hear from you if you are looking for:, , Start-up energy in a passionate team environment, Exponential growth (5 straight quarters of 100%+ quarter over quarter growth), Open communication environment based on high integrity values, Rockstar teammates, Profitable business model in a $170 billion market, , About the role:, , We are looking for a Data Engineer who is passionate and motivated to make an impact in creating a robust and scalable data platform. In this role, you will have ownership of the company’s core data pipeline that powers our metrics, marketing, strategic decision making, and important parts of our product. You will also leverage data expertise to help evolve data models in various components of the data stack. You will be working on architecting, building, and launching highly scalable machine learning algorithms to support the company’s products and operations. Your efforts will allow access to business and user behavior insights, leveraging the data to fuel other functions such as Analytics, Data Science, Marketing and Operations., , Responsibilities:, , Managing our ETL pipelines , Business Intelligence:, Determine and procure tooling/platform, BI request workflow (business need -> report), Version control of queries / dashboards, Determine and maintain correctness of data (data quality), Machine Learning:, Select and deploy platform for ML, Determine architecture for Jerry interacting with and utilizing the ML output in business logic (i.e. APIs, etc), Take MVP model built by data scientist and ‘productize’ it (i.e. implement/integrate it in production system), Reports on performance of deployed ML models, , Requirements:, , Proficient in SQL, especially with Postgres dialect., Expertise in at least one programming language for implementing ML models and corresponding client APIs. Familiarity with NodeJS (our product dev language) is a plus., Experience in packaging and deploying ML code in production environments. Experience with Docker required. Experience with Kubernetes is a plus., Experience with BI software (preferably Metabase, Qlikview or Tableau)., Experience with deploying and maintaining data infrastructure in the cloud (experience with AWS Lambda -> AWS Kinesis -> AWS Redshift -> Metabase BI & AWS RDS preferred), Comfortable working directly with data analytics to bridge business requirements with data engineering, , About Jerry.ai, , Jerry.ai is an AI powered personal concierge for your car and home. Our mission is to make all aspects of car & home ownership hassle-free and effortless. We started with car insurance and have built a magical experience for saving money on insurance. Since our launch 15 months ago, we have been growing very fast (doubling revenue every quarter) and our users love the product (rating 4.5 in the app store)., , Jerry.ai is founded by serial entrepreneurs who previously built and scaled YourMechanic (“Uber for car repair,” with the largest online traffic in car space in the US). We are based in Silicon Valley and have multiple offices in the US and Canada. We are backed by Y-Combinator, SV Angel, Funders Club, and many other prominent Silicon Valley Investors., , , Location: , , Toronto, Canada, Palo Alto, California, China (working remote)","Jerry.ai is a ML powered concierge for car/home owners with the mission to make car & home ownership easy peasy. Imagine having a personal assistant on text 24/7 for all car/home needs (shop for your insurance, help with renewal of car registration, provide expert advice to deal with repairs/upgrades - all for free!). 

We are based in the San Francisco Bay Area with offices in Palo Alto, Toronto, and Buffalo, NY. We were incubated at Y-combinator in 2017 and has raised over $30M. Jerry.ai is being built by serial entrepreneurs who built and scaled YourMechanic (“Uber for car repair” in US), Match.com, LendingClub, and Amazon.

Why did we name the company Jerry? We were inspired by the movie Jerry Maguire. In it, Tom Cruise plays a sports agent who goes above and beyond for his clients. We believe artificial intelligence can be used to create a personal Jerry McGuire for everyone. An agent who is tireless, incredibly smart, has access to all the data all the time, works only in your interest, and knows all the tips and tricks to help you make car & home ownership easy peasy."
2020/06/08 05:12:17,https://www.linkedin.com/jobs/view/1877404538/?eBP=JOB_SEARCH_ORGANIC&recommendedFlavor=COMPANY_RECRUIT&refId=1249d27b-471a-4c63-abc6-102a9dd4b3d6&trk=flagship3_search_srp_jobs,Machine Learning Engineer,Autodesk,"Toronto, CA",Posted 6 days ago,304,"['Python (Programming Language)', 'Machine Learning', 'C++', 'SQL', 'Java', 'Data Analysis', 'MATLAB', 'C (Programming Language)', 'Deep Learning', 'Microsoft Office']","['121 Entry level applicants', '54 Senior level applicants', '3 Manager level applicants', '2 VP level applicants']","['304% Applicants', '25% Applicants in the past day']",,Full-time,"['Computer Software', 'Design', 'Information Technology & Services']","Machine Learning Engineer, Location: Toronto- Canada, Job ID: 20WD40406, , Position Overview, , The Fusion 360 Machine Learning team is looking for a driven and naturally curious machine learning engineer who can hit the ground running in fast paced, complex environment. We are a small, agile research team that are intensely curious and passionate about the impact of artificial intelligence on the product design and manufacturing industry., , In this role, you will play a critical role in bridging the gap between software developers and machine learning researchers. You will pioneer technology that will be the backbone of this next generation of design and manufacturing software. You will be actively problem solving how we can accelerate progress on bringing cutting edge research to product and work collaboratively on working prototypes to show our customers and our leadership team. When the time comes to move any feature into product, you will be a strong interface with product engineering to plan the integration into Fusion 360. You are excited by the idea of working on a wide range of tasks from data curation to model tuning and validation to building compelling presentations to explain your results to a broad set of stakeholders., , Responsibilities, Understand business objectives and develop models that help to achieve them, along with metrics to track their progress, Gather and process large batches of unique and varied data (3D geometry, 2D drawings, simulation output, and design workflow data), Build new pipelines for efficient data processing and verifying data quality, Train models and tune their hyperparameters, Analyze the errors of the model and design strategies to overcome them, Research and implement best practices for scaling our ML operations, Develop working prototypes to showcase and validate your solution, Interface with relevant software development teams to take models to production, Continually monitor AI research frontier and technology trends to identify opportunities for improvement or reinvention, Regularly present progress to a broad base of stakeholders, , Minimum Qualifications, BS, MS, or PhD in Mathematics, Statistics, Computer Science, Engineering, Physics, or equivalent, Proficient in Python (and basic libraries for ML), C++, Javascript, Great understanding of fundamental CS algorithms and their scaling behaviors, Strong data modeling and data architecture skills, Practical experience applying machine learning algorithms and libraries to a business problem, Knowledge of standard deep learning frameworks such as TensorFlow and PyTorch, Excellent at communicating data and results effectively, both verbally and visually, Strong documentation skills in the hand off of code and software architecture, A self-starter with initiative to search for solutions and execute on problems with minimal supervision, Comfortable working in newly forming ambiguous areas where learning and adaptability are key skills, Ability to break down a large problem into small components and provide a clear solution for each, , Preferred Qualifications, Experience with cloud data processing, training, deployment, or operations (e.g. AWS, GCP), Knowledge of the design and manufacturing industry, Experience with Autodesk or competitive products (CAD, CAE, CAM, etc.), , About Autodesk, , With Autodesk software, you have the power to Make Anything. The future of making is here, bringing with it radical changes in the way things are designed, made, and used. It’s disrupting every industry: architecture, engineering, and construction; manufacturing; and media and entertainment. With the right knowledge and tools, this disruption is your opportunity. Our software is used by everyone - from design professionals, engineers and architects to digital artists, students and hobbyists. We constantly explore new ways to integrate all dimensions of diversity across our employees, customers, partners, and communities. Our ultimate goal is to expand opportunities for anyone to imagine, design, and make a better world., , Americas-Canada-Ontario-Toronto, , Engineering","Autodesk makes software for people who make things. If you’ve ever driven a high-performance car, admired a towering skyscraper, used a smartphone, or watched a great film, chances are you’ve experienced what millions of Autodesk customers are doing with our software. Autodesk gives you the power to make anything. 

Over 100 million people use Autodesk software like AutoCAD, Revit, Maya, 3ds Max, Fusion 360, SketchBook, and more to unlock their creativity and solve important design, business and environmental challenges. Our software runs on both personal computers and mobile devices and taps the infinite computing power of the cloud to help teams around the world collaborate, design, simulate and fabricate their ideas in 3D.
 
We provide exceptional compensation/benefit packages and we’d love for you to join us. We’re proud to be an equal opportunity employer and we consider all qualiﬁed applicants without regard to race, gender, disability, veteran status or other protected category. To see our culture in action, check out #AutodeskLife.

We are headquartered in the San Francisco Bay Area and have more than 10,000 employees worldwide."
2020/06/08 05:12:53,https://www.linkedin.com/jobs/view/1890096115/?eBP=NotAvailableFromVoyagerAPI&recommendedFlavor=SKILL_ASSESSMENTS&refId=1249d27b-471a-4c63-abc6-102a9dd4b3d6&trk=flagship3_search_srp_jobs,Data Analyst (Customer Success),Later,"Toronto, CA",Posted 5 days ago,335,"['Data Analysis', 'SQL', 'Python (Programming Language)', 'Teamwork', 'R', 'Microsoft Excel', 'Microsoft Office', 'Tableau', 'Microsoft PowerPoint', 'Data Visualization']","['41 Entry level applicants', '33 Senior level applicants', '5 Manager level applicants']","['335% Applicants', '17% Applicants in the past day']",Entry level,Full-time,"['Information Technology & Services', 'Computer Software', 'Internet']","What started as the result of a hackathon in 2014 is now the world’s #1 Instagram marketing platform. Later was built on the idea that social media management should be easy, quick, and affordable. Six years and hundred thousand users later, we’re still going strong., , We’re looking for people who can help us build something great for our customers—from content writers, designers to developers. So if you’re the kind of person who really cares about making something meaningful, then keep reading., , Our Values, , Our core cultural values are manifested in our practices and processes every day. We highly value transparency and fairness in everything we do. We look for people who like to move quickly, are ambitious yet humble and have a great sense of humour. If you have a mischievous spark of fun, that’s even better., , You Have, , A natural tendency to take initiative, achieve results and generally #GSD., A desire to constantly stay organized and create efficiency using technology, bringing order to chaos and uncertainty., Teamwork is your middle name. You want to brainstorm with the best of them and are continually looking for ways to do it better., A humbleness to recognize that sometimes you’ll need to apologize and admit mistakes (we’re all human after all!), Understand and work well in startup culture - be able and willing to take on all sorts of tasks and responsibilities., , We list our values and beliefs first because they are non-negotiable; if you're still reading then check out some of the responsibilities you will own., , What You Will Be Doing, , As a Data Analyst on the Customer Success team, you will build visibility and generate analytical insights around customer product usage, impact of Success led projects and initiatives, and most importantly customer retention. Your ultimate goal is to help Later’s Customer Success team have all the necessary data insights to understand customers retention in order to align all teams on how best to increase retention over time, , Reporting to the Head of Customer Success, this role will own data analysis and retention insights within the organization. The Customer Success team at Later are the champions of retention and our mission is to help Later customers achieve their visual marketing goals and desired outcomes with the help of our product. Within the Success team, the Data Analyst will find insights that can be leveraged to understand all aspects of product usage and retention to guide our team on the best strategies to help our customer achieve their goals. With a rapidly growing user-base in the millions, the ideal candidate for this role is an ambitious strategic thinker who loves to test and thinks about the bigger picture., , Embedded within the Success team, the Data Analyst will work closely with Onboarding, Education, and Engagement to uncover critical insights and develop hypotheses. You will be collaborating with Marketing, Growth, and Product teams to approach retention holistically., , Responsibilities, Data ownership: Support the Success team in understanding the retention by collecting, cleaning, and maintaining data pipelines from numerous sources., Create visibility: Assemble and maintain dashboards that will allow the Success team to visualize data for both scheduled and ad-hoc reporting, Find opportunities: Perform in-depth data analyses to identify user behavior and interpret findings within our userbase to drive stronger retention, Surface insights: Dive into Later’s subscription products and subscriber behavior, including funnel analysis, pricing and revenue analysis, user segmentation, user profitability, retention by cohort, and more, Iterative reporting: Measure and report performance of all campaigns and assess against goals (ROI and KPIs). Build, maintain, and monitor KPI dashboarding on channel and overall Customer Success team performance., Interpret results: Monitor, analyze, and inform the Success team on ongoing retention experiments, Forecasting: Support revenue and lifetime value forecasting of subscribers across different offerings, , Need To Haves, B.S. in economics, decision science, statistics, engineering, applied math, operations research, or a related quantitative field (or equivilent), At least 2+ years of post-collegiate in a quantitative field in technology, subscription services, or equivalent post-graduate experience, Bonus: Experience in a SMB SaaS environment, Experience working with relational databases and SQL query languages, Experience working with cross-functional teams in a fast-paced environment, Quantitative forecasting experience, Significant experience with Excel, Ability to communicate the results of your analyses clearly to both technical and non-technical stakeholders, , Nice To Haves, Experience with Mixpanel and/or Amplitude, Proficient with statistical packages in R, Python, and/or SAS, Salary Range, $80,000 - $107,000, , About Later, , Later is proudly founded and based in Vancouver. We pleased to offer all our employees a competitive salary, a chance to participate in the success of the company through equity, medical and dental benefits and a wellness program., , Working Locations:, , Product and Development roles are based out of our Vancouver headquarters. If you are not located in Vancouver, but interested in relocating for the role let us know!, , Whereas, roles on our Marketing and Customer Experience teams are open to remote candidates based out of Toronto and London, UK, in addition to working out of our Vancouver headquarters., , How To Apply, , If you’d like to work with us, please submit your resume, cover letter, and any links showcasing your skill set through this posting. This is the best place to submit your application for it to be reviewed by our team., , Note: Later does not work with recruitment agencies to fill open positions. We will not be accepting requests to work with agencies.","About Later (previously Latergramme):

Founded as the first-to-market Instagram scheduler in 2014, Later (formerly Latergramme) has grown from a simple Instagram tool to the #1 visual marketing platform for Instagram, Facebook, Twitter, and Pinterest.

Now with over 2 million users globally, Later is a member of the Instagram Partner Program. 

We believe that social media has become a visual experience, and we’ve designed our platform to help you visually plan and schedule your photo and video content. 

Later helps streamline your social media strategy so you can set yourself up for more sales and success. Our features focus on visual scheduling, media management, marketing and analytics. 

Here at Later, our goal is to simplify Instagram marketing and make it accessible for all businesses. Subscribe to the Later blog and sign up for our free Instagram marketing courses!"
2020/06/08 05:13:29,https://www.linkedin.com/jobs/view/1896503769/?eBP=JOB_SEARCH_ORGANIC&recommendedFlavor=SKILL_ASSESSMENTS&refId=1249d27b-471a-4c63-abc6-102a9dd4b3d6&trk=flagship3_search_srp_jobs,Data Scientist - Insights & Innovation,Equifax Canada Co.,"Toronto, CA",Posted 1 day ago,102,"['Python (Programming Language)', 'Data Analysis', 'SQL', 'Machine Learning', 'R', 'Data Science', 'Statistics', 'Microsoft Excel', 'Microsoft Office', 'Data Visualization']","['42 Entry level applicants', '23 Senior level applicants', '1 Manager level applicant']","['102% Applicants', '5% Applicants in the past day']",Mid-Senior level,Full-time,"['Information Technology & Services', 'Computer Software', 'Financial Services']","Would you like to work in a fully Agile environment? Your main objective as the Data Scientist at Equifax will be to partner with clients and internal stakeholders to deliver innovative decision science models & attributes that utilize Equifax’s data assets., Who are we at Equifax?, We are a global information solutions company that uses trusted unique data, creative analytics, technology and industry expertise to power businesses and individuals around the world. We help our clients by transforming data into insights and utilize our technology solutions to power more informed business and personal decisions., Regardless of location or role, the individual and collective work of our people makes the difference in our business., We are looking for individuals who can help us disrupt the marketplace. You will do this by selling leading-edge data, analytics and technology to businesses that will deliver unparalleled customized insights that enrich both the performance of their business and the lives of their customers., About the Job, Equifax is looking for an experienced Data Scientist to join its Canadian team. As a Data Scientist at Equifax, you will collaborate directly with both internal partners and clients to deliver innovative decision science models & attributes that leverage Equifax’s vast data assets. These include decision areas covering the credit lifecycle, geodemographic & marketing attributes, ratings & fraud models, as well as any new areas where data driven decision making can be informed by predictive modelling including advanced modeling techniques and machine learning when applicable., Responsibilities of the Data Scientist include:, Project management including defining business and technical requirements, resource planning and analytic solution design, Effectively communicate analytical results to key stakeholders using strong data visualizations, superior presentation skills and business language to emphasize the so what of the analysis, Build and create advanced machine learning algorithms such as regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc, Quality control of all analytical output, Requirements:, Ideally, you will not only have strong technical experience but demonstrate creativity and inquisitiveness and a proven ability to drive business results with their data-based insights. You will need to be comfortable working with a wide range of stakeholders and functional teams. You will also need to have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes. , Required Skills of the Data Scientist include:, 3+ years’ Data Science experience with expert knowledge of Python in a large data environment, 3+ years’ experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, and neural networks, Proven hands-on experience designing and building analytical solutions to solve real world problems, with limited direct supervision required, Solid communication / presentation skills, Creativity & idea generation, Preferred Skill of the Data Scientist include:, Background in financial services, telecommunications or utilities (not essential), Experience in working with Credit Data, Experience with data visualization tools (Spotfire, Tableau, Qlik) is an asset, Knowledge of R, SAS or SQL, Education, Bachelor’s or advanced degree in a quantitative discipline such as Engineering, Economics, Mathematics, Statistics, or Physics (essential), Master’s level degree in a business-related field/MBA (preferred), Primary Location:, CAN-Toronto-5700 Yonge, Function:, Function - Data and Analytics, Schedule:, Full time","Equifax (NYSE:EFX) is a $2 billion global information solutions company with a heritage dating back 113 years. With its Canadian Headquarters in Toronto, Equifax operates or has investments in 18 countries spanning 4 continents and is a member of Standard & Poor’s (S&P) 500® Index. 

Recognized by the financial community as a global leader in consumer and commercial information solutions, Equifax provides businesses of all sizes and consumers with information they can trust. We organize and assimilate data on more than 572 million consumers and 81 million businesses worldwide, and use sophisticated advanced analytics and proprietary technology to create and deliver customized solutions that enrich both the performance of businesses and the lives of consumers.

Equifax provides clients with faster and easier ways to find, approve, and market to the “right customer”. Our success in meeting these goals is based on strategic growth, continuous product development, and technology innovation to deliver powerful solutions."
2020/06/08 05:14:06,https://www.linkedin.com/jobs/view/1860831671/?eBP=CwEAAAFyky6arA8IHRRg1Fp41Am-xKQSLIfMYaywnDSz3wGpHxGHv5kDHl9C1_s02j5TfkMMJJ1D-TFn-8II_z4cFdmJ1ZFVvB3PaZuhYWV1FxECQdr0WvGWaSaij4pSpXuq8zpmKSepA276DHSAasAuORmtyklITdTYfodNadEH9rp71XMW7JIWmCvGH6gvloNhSUbHafc5WOxz2SDvaMPed7COuRralD72cVxkgmNxVFlURv9kQFIb-YPjCsSirgvyhx6UzMDa0urb8OvsZ5IIfxnpeV-dJRc3JmYWUCXvLXxQ1xc_banhArZvjqDIRjgUel9XJKN_b95mr_ev6BWPFAxI-x51VLHXBCX4SXp0iBPpI5vf6GlnXV2-LzenJRVQuu_TTsNdjnBoGYmp&recommendedFlavor=COMPANY_RECRUIT&refId=1249d27b-471a-4c63-abc6-102a9dd4b3d6&trk=flagship3_search_srp_jobs,Data Engineer,Capco,"Toronto, Ontario, Canada",Posted 3 weeks ago,,"['SQL', 'Python (Programming Language)', 'Java', 'HTML', 'Hadoop', 'Machine Learning', 'JavaScript', 'Microsoft Office', 'Apache Spark', 'MySQL']","['35 Entry level applicants', '23 Senior level applicants']",,Mid-Senior level,Contract,['Financial Services'],"Let’s Talk About You, You want to Own Your Career. You’re serious about rising as far and as fast as your work and achievements can take you. And you’re ready to write the next chapter of your career story: a challenging and rewarding role as a Capco Data Engineer.,   Let’s Get Down To Business, Capco is looking for talented, innovative, and creative people to join our development team to work on a number of projects and applications with a Data focus within the Digital practice., Fitting that description, you will also need to be personally motivated to work in a team where clients become colleagues too.,   Responsibilities, Produces high quality complex, deliverables with minimal input from stakeholders, Manage full software lifecycle for medium complexity projects from requirements, to design, to implementation, to testing, Develop and maintain back end solutions using cutting edge technologies and products, Work with Scrum Masters and product owners to priorities and deliver solutions using an Agile environment, Build reusable code and libraries for future use and follow emerging technologies, Mentor and train junior developers,   Education/Experience, Bachelor’s degree (preference given to Computer Science, Engineering, Gaming and STEM-based majors) or equivalent experience, Three (3) or more years of experience as a Full-stack Data Engineer/developer on Data driven projects, Strong understanding of the full development lifecycle including requirements, architecture, design, development and testing, Working knowledge of JavaScript (ES6+), ReactJS, Redux, Development experience with Core Java / Scala, Experience working with Multithreading, Websockets, REST, Familiarity working MongoDB, SQL, Experience working with JUnit, Mockito, Ability to balance competing priorities in a very dynamic and fast-paced environment, Excellent detail-oriented, problem solving skills and the ability to quickly learn and apply new concepts, principles and solutions, Must have excellent communication skills (verbal and written), , Show Us What You’ve Got, It will be very useful if you have some or all of the following skills:, Understanding of big data and distributed programming concepts, Experience working with ASW, GCloud, Docker, Kubernetes, Experience working with Microservices, CQRS, EventSourcing, Experience working with Spring, Akka, Spark, Experience working with Reactive Streams (Rx, Akka, Reactor), Strong organizational and communication skills, Experience working in an Agile environment, Experience working with code versioning tools, Experience working with build, packaging and continuous integration tools and frameworks,   Professional experience is important. But it’s paramount you share our belief in disruptive innovation that puts clients ahead in a tough market. From day one, your key skill will be to perceive new and better ways of doing things to give your clients an unfair advantage.,   Now Take the Next Step, If you’re looking forward to progressing your career with us, then we’re looking forward to receiving your application., Capco is well known for its thought leadership and client-centric model that distinguishes it from other consulting firms. Capco’s strong technology and digital knowledge base, it’s global experience of the Financial Service enables us to deliver projects from strategy through to delivery. We are committed to providing new areas of expertise from which our clients will greatly benefit. We have:, Access to industry-focused talent globally, Ability to leverage best-of-breed, innovative products and solutions for complex architecture and large-scale transformation, Extended global geographic market reach, Ability to capitalize on our client footprint and deep domain expertise within financial services, For more information about Capco, visit www.Capco.com., Capco is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, marital status, genetic information, national origin, disability, veteran status, and other protected characteristics.","Capco is a global management consultancy with a focus in financial services including banking and payments, capital markets, wealth and asset management, and insurance, plus a dedicated energy division. We combine innovative thinking with unrivalled industry knowledge to deliver business consulting, digital, technology and transformational services. Our collaborative and efficient approach helps clients reduce costs, manage risk and regulatory change while increasing revenues. Visit us at www.capco.com and follow us on Twitter @Capco."
2020/06/08 05:14:43,https://www.linkedin.com/jobs/view/1852307164/?eBP=NotAvailableFromVoyagerAPI&recommendedFlavor=SKILL_ASSESSMENTS&refId=1249d27b-471a-4c63-abc6-102a9dd4b3d6&trk=flagship3_search_srp_jobs,Data Engineer,"Continental Technology Solutions,Inc","Toronto, CA",Posted 1 month ago,19,"['Python (Programming Language)', 'SQL', 'C++', 'Data Analysis', 'HTML', 'Machine Learning', 'JavaScript', 'English', 'Web Development', 'MySQL']",['2 Entry level applicants'],"['19% Applicants', '0% Applicants in the past day']",Entry level,Full-time,"['Information Technology & Services', 'Computer Software', 'Financial Services']","""The Cloud and Big Data Team is looking for a Data Engineer to enable the usage of big data on Enterprise Data Lake across the firm. You will be responsible for developing, constructing and testing large-scale data processing systems based on AWS cloud., Through close partnership with investment professionals, you will see firsthand how your contribution is delivering long-term value to the CPP Fund for the benefit of 22 million CPP contributors and beneficiaries., , The Opportunity, , "" Work in a fast-paced environment collaborating with developers, data engineers and architects., "" Develop dataset processes for data modelling, mining and production., "" Ensure architecture will support the requirements of CPPIB business., "" Prepare, transform, combine and manage structured and unstructured data for use by CPPIB business users., "" Recommend ways to improve data reliability, efficiency and quality., "" Define and shape CPPIB's future technology and research process., Position Requirements, "" University degree in Engineering or Computer Science preferred., "" Deep experience working with big data including cleaning/transforming/cataloging/mapping/ etc., "" Familiar with cloud technology best practices to enable the distribution and analysis of big data on the cloud (formatting/partitioning/etc.)., "" Experience of ETL pipelines, managing multiple datasets and providing necessary support., "" Experience using cloud providers and associated services (AWS/GCP/etc.), "" Familiarity working with data lakes using S3/Redshift., "" Exposure to big data workflows and analytics tools (Spark/EMR/Databricks/Cassandra)., "" Deep proficiency with either Python or Scala with experience using spark, pandas or pyspark., "" Familiar with one or more analytic tools such as Tableau, Looker, Matplotlib., "" Experience building flexible solutions that can adapt quickly to changing requirements., "" Ability to work in an entrepreneurial environment and be a self-starter., , Vignesh, 647-362-07464, vignesh@ctsincorp.com","Continental Technology Solutions is one of the fastest growing Information Technology Services, IT staffing and management consulting company headquartered in Houston, Texas with extensive transcontinental operations. We provide innovative and dynamic business solutions. 

Continental Technology Solutions has garnered an impressive track record of delivering successful results, with a noteworthy client list that includes mid-sized to Fortune 500 companies, having offices and strong market presence in United States, United Kingdom, Canada, Australia, Singapore, Malaysia, Hong kong and India. 

With more than decades of experience at delivering technology and IT Staffing solutions and we are a talent-driven, talent acquisition company providing technology experts, individual consultants, project teams, project development and strategic outsourcing services to clients in a wide range of industries in United States, United Kingdom, Canada, Singapore , Malaysia and India. We leverage our recruiting expertise to deliver high-end consulting services for a variety of engagements. 

We have formed several vertical industry practice groups to focus developing solutions targeted to your business.The experts in our practice groups are delivering real world domain experience to our customers, helping them optimize their technology and business processes

• Banking & Financial Services
• Healthcare & Life Sciences
• Insurance
• Logistics
• Manufacturing
• Retail
• Telecom
• Energy & Utilities

We specialize in the following areas and are currently providing services and technology solutions

• Cloud and Big Data Solutions
• Web /Enterprise Application Development 
• Mobile Development
• Analytics , Business Intelligence / Data warehousing
• Database Development and Administration (Database Architecture, Data Modeling)
• Project Management
• Requirements & Analysis
• Quality Assurance"
2020/06/08 05:15:19,https://www.linkedin.com/jobs/view/1877047321/?eBP=CwEAAAFyky6arIXgELVm7aY8lSmg-tOPLWW0M7aKI0p815T4NNmuhITw57dF44Zu9zgAfMook-GYSV7z6Qic3cjSJlMApZosfE0jGILh3zi7f2dTqOYDpz9cM6ArVy2Y3k1WQTDBd8Z_PRjRJ7vgIG2FSBPhZrX5yl-4pyCbRBYpCUv57gIYn7ZVs3LPmwoC-0uo0IxwbtiznLYEvdkDPBHfvhCseePUNl6zZw4yod6LbYCA3z8WYV5KnNdiXODX9AhfMlDw22vdf_iJhEUMmBqx-bYGZBWlnqoWF1e7yln1tdHFrD7jcF1tNn_tiCg1esQPg3B1BoRWDVOmHZ6S63MWA0KiPjLZzguHcSjO_eIp&refId=1249d27b-471a-4c63-abc6-102a9dd4b3d6&trk=flagship3_search_srp_jobs,Data Engineer (Toronto; Silicon Valley),Jerry.ai,"Toronto, Ontario, Canada",Posted 6 days ago,201,"['Python (Programming Language)', 'SQL', 'Data Analysis', 'Machine Learning', 'Java', 'Data Science', 'C++', 'Microsoft Office', 'Microsoft Excel', 'Tableau']","['57 Entry level applicants', '40 Senior level applicants', '2 VP level applicants', '2 Manager level applicants']","['201% Applicants', '19% Applicants in the past day']",Entry level,Full-time,['Internet'],"We’d love to hear from you if you are looking for:, , Start-up energy in a passionate team environment, Exponential growth (5 straight quarters of 100%+ quarter over quarter growth), Open communication environment based on high integrity values, Rockstar teammates, Profitable business model in a $170 billion market, , About the role:, , We are looking for a Data Engineer who is passionate and motivated to make an impact in creating a robust and scalable data platform. In this role, you will have ownership of the company’s core data pipeline that powers our metrics, marketing, strategic decision making, and important parts of our product. You will also leverage data expertise to help evolve data models in various components of the data stack. You will be working on architecting, building, and launching highly scalable machine learning algorithms to support the company’s products and operations. Your efforts will allow access to business and user behavior insights, leveraging the data to fuel other functions such as Analytics, Data Science, Marketing and Operations., , Responsibilities:, , Managing our ETL pipelines , Business Intelligence:, Determine and procure tooling/platform, BI request workflow (business need -> report), Version control of queries / dashboards, Determine and maintain correctness of data (data quality), Machine Learning:, Select and deploy platform for ML, Determine architecture for Jerry interacting with and utilizing the ML output in business logic (i.e. APIs, etc), Take MVP model built by data scientist and ‘productize’ it (i.e. implement/integrate it in production system), Reports on performance of deployed ML models, , Requirements:, , Proficient in SQL, especially with Postgres dialect., Expertise in at least one programming language for implementing ML models and corresponding client APIs. Familiarity with NodeJS (our product dev language) is a plus., Experience in packaging and deploying ML code in production environments. Experience with Docker required. Experience with Kubernetes is a plus., Experience with BI software (preferably Metabase, Qlikview or Tableau)., Experience with deploying and maintaining data infrastructure in the cloud (experience with AWS Lambda -> AWS Kinesis -> AWS Redshift -> Metabase BI & AWS RDS preferred), Comfortable working directly with data analytics to bridge business requirements with data engineering, , About Jerry.ai, , Jerry.ai is an AI powered personal concierge for your car and home. Our mission is to make all aspects of car & home ownership hassle-free and effortless. We started with car insurance and have built a magical experience for saving money on insurance. Since our launch 15 months ago, we have been growing very fast (doubling revenue every quarter) and our users love the product (rating 4.5 in the app store)., , Jerry.ai is founded by serial entrepreneurs who previously built and scaled YourMechanic (“Uber for car repair,” with the largest online traffic in car space in the US). We are based in Silicon Valley and have multiple offices in the US and Canada. We are backed by Y-Combinator, SV Angel, Funders Club, and many other prominent Silicon Valley Investors., , , Location: , , Toronto, Canada, Palo Alto, California, China (working remote)","Jerry.ai is a ML powered concierge for car/home owners with the mission to make car & home ownership easy peasy. Imagine having a personal assistant on text 24/7 for all car/home needs (shop for your insurance, help with renewal of car registration, provide expert advice to deal with repairs/upgrades - all for free!). 

We are based in the San Francisco Bay Area with offices in Palo Alto, Toronto, and Buffalo, NY. We were incubated at Y-combinator in 2017 and has raised over $30M. Jerry.ai is being built by serial entrepreneurs who built and scaled YourMechanic (“Uber for car repair” in US), Match.com, LendingClub, and Amazon.

Why did we name the company Jerry? We were inspired by the movie Jerry Maguire. In it, Tom Cruise plays a sports agent who goes above and beyond for his clients. We believe artificial intelligence can be used to create a personal Jerry McGuire for everyone. An agent who is tireless, incredibly smart, has access to all the data all the time, works only in your interest, and knows all the tips and tricks to help you make car & home ownership easy peasy."
2020/06/08 05:15:56,https://www.linkedin.com/jobs/view/1869065675/?eBP=CwEAAAFyky6arOwoziQInmpIYl36TZcZEFOloA_b48-WyRqVVAyVKtqpZ_hn6ARPWmBBgpvn1rM0h9LKbHeqJ-2lKONSH3lw_TbAe3H_TfrdH0uNOKpgovIZu-67RoAuOAkK3rzy0aEoT1T73ef7hpDW-FL1CyaUVkwPhbdbtzUBP71lHb56qtYCSi4Q3_cnpM4m_ALLdmNDei3zRAPKyKBql7BY9h2NePpKa8NvmKMEqpvcZBLSsHpVKA-5YbTLsLVJdVcReWHc991zgkV64Y5RSwEK8O1v8NrVnbdfLvs4xBIcMZpJnnjBKQeYBeo8CcJnubl36Sm5XNBZCzTTRyz6sr0BFeiPLFh1EVRWqL5enxw7DKoz8_RI1kNsUIDBewL2DQs7meOhXmPHc6nRSiQ&recommendedFlavor=SCHOOL_RECRUIT&refId=1249d27b-471a-4c63-abc6-102a9dd4b3d6&trk=flagship3_search_srp_jobs,Data Analyst,Toptal,"Toronto, CA",Posted 2 weeks ago,609,"['SQL', 'Data Analysis', 'Python (Programming Language)', 'R', 'Microsoft Excel', 'Microsoft Office', 'Tableau', 'Microsoft PowerPoint', 'Microsoft Word', 'Data Visualization']","['170 Entry level applicants', '131 Senior level applicants', '15 Manager level applicants', '3 VP level applicants']","['609% Applicants', '7% Applicants in the past day']",Entry level,Full-time,['Internet'],"About Toptal, , Toptal is a global network of top talent in business, design, and technology that enables companies to scale their teams, on-demand. With $200+ million in annual revenue and over 40% year-over-year growth, Toptal is the largest fully distributed workforce in the world., , We take the best elements of virtual teams and combine them with a support structure that encourages innovation, social interaction, and fun (see this video from The Huffington Post). We see no borders, move at a fast pace, and are never afraid to break the mold., , Position Description, , Are you looking to play a meaningful role in how an organization uses data to make confident, trustworthy decisions? Toptal prides itself on being data-centric, and we are looking for a Data Analyst to drive business impact and better decision making by laying the data foundation for an elite analytics function!, , Our Data Analysts focus on building a data environment that is conducive to analytics. Crafting such an environment will require data governance, data modeling, technical communication, quality control, and in-depth data analysis. You will be the product owner for our data warehouse–while you won’t directly own ETL processes, you will provide SQL logic, priorities, and requirements to our Data Engineering team., , This role sits within our new Business Analytics Center of Excellence and will ensure reliable data is available for all downstream data users (business analysts, data scientists, and report developers). Positive relationships with both data engineers and business analysts are critical, and ability to think independently and not just take orders. To be successful in this role, you must live and breathe SQL daily and be a critical thinker, problem-solver, and self-starter., , This is a remote position that can be done from anywhere. Due to the remote nature of this role, we are unable to provide visa sponsorship. Resumes and communication must be submitted in English., , Responsibilities, Translate business definitions into SQL logic that can be embedded in our data warehouse and used for reporting and analytics, Proactively extract insights from data analysis and find opportunities to improve data operations, accuracy, coverage, integrity, structure, and general usability, Map business processes to their corresponding data flows, Build a data strategy and policies to govern data inputs, outputs, processing, access, security, and usage, Document all data elements, metrics, dimensions, sources, limitations, logic, usage, and definitions in comprehensive data dictionaries, Provide requirements, prioritize, and manage the backlog with Data Engineering, Work closely with colleagues to empower decision making that is fueled by data, Train end users on data usage, complexities, nuances, and limitation, , , In The First Week Expect To, Onboard and integrate into Toptal, Rapidly begin learning about Toptal’s history, culture, and vision, Shadow critical teams within the organization to learn the core of Toptal’s operations and capabilities, including Growth, Talent Operations, Enterprise, and SMB, , , In The First Month Expect To, Understand the data generated through company operations and activities and where/how that data is stored, Understand our ETL processes, timing, tools, monitoring, roadmap, and challenges, Understand our source systems, and where they fit into our business processes, , , In The First Three Months Expect To, Develop a proficiency of data elements, Begin standardizing definitions and building SQL logic to push definitions into the data layer, Begin certifying metrics and dimensions, checking for quality and accuracy, Begin documenting data flows, definitions, calculation methodologies, and data elements in detailed data dictionaries, , , In The First Six Months Expect Tol, Start to transition users away from old metrics and definitions, Contribute to the alignment and standardization of metric definitions across the company, , , In The First Year Expect To, Play a critical part in setting up our new Center of Excellence for success, Be seen as an authority on all things data, Have established a centralized, certified, official data repository as a single source of truth, , , Requirements, 3+ years of experience in data science, data analysis, analytics, business intelligence, or reporting, Experience in doing exploratory/raw data analysis, data modeling, and data governance (quality, accuracy, coverage, security, etc.), Experience translating business logic and objectives into SQL code and linking data and analytics to business strategy and operations to drive real impact, Detail obsessed, systematic, and thorough, Strong professional skepticism; you will need to challenge assumptions, Very proficient in SQL; experience with R, Python, or MATLAB a plus, Experience with BI tools (Tableau, Qlik, PowerBI, etc.), Solid technical background in math, science, engineering, or statistics, Working knowledge of business processes and statistics, Extraordinary teammate that builds positive relationships and establishes trust with business leaders, engineers, and business analytics colleagues, Outstanding written and verbal communication skills, and the ability to explain complex issues in a simple and intuitive way, Work independently and across functions; take ownership of quality, accuracy, and timeliness of your work, You must be a world-class individual contributor to thrive at Toptal. You will not be here to tell other people what to do., , For Toptal Use Only: #canada #remote","Toptal is a global network of the top talent in business, design, and technology that enables companies to scale their teams, on-demand. With $200+ million in annual revenue and over 40% year-over-year growth, Toptal is the largest fully distributed workforce in the world."
2020/06/08 05:17:30,https://www.linkedin.com/jobs/view/1890003255/?eBP=NotAvailableFromVoyagerAPI&recommendedFlavor=SCHOOL_RECRUIT&refId=205722bd-0386-4d74-aec5-a36e0710a3ae&trk=flagship3_search_srp_jobs,Data Engineer,Michael Page,"Toronto, CA",Posted 5 days ago,22,"['Python (Programming Language)', 'SQL', 'Machine Learning', 'R', 'Data Analysis', 'Data Visualization', 'Microsoft Excel', 'Tableau', 'Google Cloud Platform (GCP)', 'Programming']","['3 Senior level applicants', '2 Entry level applicants']","['22% Applicants', '2% Applicants in the past day']",Entry level,Full-time,['Financial Services'],"Data Engineer, Growth Opportunity, Great Benefits, About Our Client, Client is disrupting the antiquated and inefficient world of insurance and financial services. Our team of world class software engineers, data scientists, and business professionals are modernizing how people obtain and manage their financial life all through our powerful platform ecosyste, , Job Description, , Our team uses a variety of data mining and analysis methods, a variety of data tools, builds and implements models, develops algorithms, and creates simulations. Our Data Engineers design and build the backbone that makes this development possible with no support from engineering (we own our stack end to end)., The Successful Applicant, Must Haves, Expertise in modeling data, At least 2 years of experience as a data engineer, Experience with Spark, Hadoop/EMR, SQL, Ability to optimize data access for speed/reliability/velocity as needed by the business, Comfort with QA'ing your own data, to include 'menial tasks' like listening to calls or scrubbing excel files to ensure everything is correct, Excellent communication ability - you can explain your work in a way that anyone on the team can understand, and you can frame problems in a way that ensures the right question is being asked., Bachelors degree in mathematics, statistics, data science or related field of study., Nice to Have, Capable of modifying an existing job to add a new field and get it into production within a day., Capable of creating a new data pipeline/job within 2-3 days., , What's On Offer, , Industry leading benefits, Contact: David Bogusz, Quote job ref: 1460803","Welcome to the Michael Page global company profile.

Michael Page has four decades of expertise in professional services recruitment. We were established in London in 1976, and over this period we've grown organically to become one of the best-known and most respected consultancies, with an office network spanning six continents. 

While size has its advantages, it doesn't define us - the nature of our organic growth means that each new office is integrated into the region that it serves. It also means that as an employer looking to hire, or as a candidate aiming to grow your career you have the best of both worlds; a team that understands the market and geography you operate in, plus the resources and expertise of an international network at your disposal.

Our teams are broken down to focus on industry, assignment type, salary level and location, so your hiring requirements or job search will all be handled by a specialist who knows your sector inside-out. We are confident that our expertise can add value to your recruitment or job search process – get in touch to find out more."
2020/06/08 05:18:07,https://www.linkedin.com/jobs/view/1893222860/?eBP=NotAvailableFromVoyagerAPI&recommendedFlavor=IN_NETWORK&refId=205722bd-0386-4d74-aec5-a36e0710a3ae&trk=flagship3_search_srp_jobs,Business Data Analyst,Moneris,"Etobicoke, CA",Posted 4 weeks ago,,,,,Associate,Full-time,"['Information Technology & Services', 'Staffing & Recruiting', 'Financial Services']","The role is responsible for designing, developing, manipulating and maintaining financial reporting systems, as well as interpreting data that influence and drive decisions. This includes identifying needs, creating process improvement solutions, working with multiple stakeholders and maintaining collaborative relationships with business partners., , To be successful in the role, the candidate brings a solid working knowledge of SQL, Tableau, Python and process automation. In addition, the candidate is a self-starter with a passion for providing various ways to improve effectiveness within the business., , You Will Be Accountable To, Meet with various business units to understand their needs, identify the business problem, determine, define and deploy predictive/prescriptive analytic solutions to meet business objectives., Prepare, extract data and perform data manipulation by using various programming language (SQL, Python etc.)., Use machine learning methods or other data mining techniques to get insights from massive datasets., Work closely with data analysts, data engineers, data scientist and other team members on projects and ad-hoc requests., Communicate approaches, findings and recommendations to business stakeholders., Strictly adhere to legal and compliance guidelines regarding access and exposure to sensitive and confidential information., Your Experience Includes, Bachelor or Masters’ degree in an analytical field of study e.g. Engineering, Mathematics, Business Analytics, Finance, Computer Science., 3 - 5 years of work experience directly related to quantitative analysis, with proven results., Familiar with tools such as SQL/Python/Data Bricks or other tools for large scale data analysis., Solid knowledge and some hands-on experience with various machine learning algorithms e.g. time series analysis, anomaly detection, cluster analysis, decision trees, random forest, SVM., Superb analytical and conceptual thinking skills to not only manipulate but also derive meaningful interpretations from data., Ability to take initiative, multi-task, and is a good team player in a fast-paced environment., Strong detail orientation is essential in this role.","Moneris is Canada's largest provider of innovative mobile, online and in-store payment solutions, processing approximately 3.5 billion transactions every year. We offer hardware, software and business solutions to more than 350,000 merchant locations of every size and industry to help transform the way they grow and operate, in payments and beyond.

Founded in 2000 with over 1,500 employees across Canada, Moneris is a hub of collaborative thinkers who challenge the status quo and are passionate about shaping the future of payments. We believe in winning for our customers by winning with each other, which is why we are committed to investing in our people to provide leading payment solutions for our customers.

If you’re interested in joining our team, please visit our career page at https://moneris.com/careers to view current opportunities."
2020/06/08 05:18:43,https://www.linkedin.com/jobs/view/1786901349/?eBP=CwEAAAFykzPw9xeI4xEQPvZX3EDGXHHQMyY1KrootdcI1uboXNR9zdzBGjIVXh0yJcli8DtXZdcxf-1bmFumW5v8DyjnJAGiL9708hRemdt2IXGfhFIGcT72yt4u_ORBVp7loNQS_ttiVAD2TmPaHeOM2En7B_do1fD95JJX-Q1plMbItN5gUUfyUeH9jbUcqvU7ieNPXvIRfAgV9NdT79poZbFfOuiTR-ORTiK64KhyO9FM7ri3UA9fhInIRL_5mUatpd3ATxYW54QwmHWR1lOQA0ZyJqhDST_eWTKi78fElsAWLdPNAplSPtpKsoQQriUvmK048FjLOqtKbs8J7UYZxl7k6Ts8p6q2vgGkLnstT5mdfS1PJsApymKlpoPzHGIiD0YKmSn_LCYJ4Wd5&recommendedFlavor=COMPANY_RECRUIT&refId=205722bd-0386-4d74-aec5-a36e0710a3ae&trk=flagship3_search_srp_jobs,Data Platform Engineer,Scribd,"Toronto, CA",Posted 2 weeks ago,86,"['SQL', 'Python (Programming Language)', 'Java', 'Data Analysis', 'HTML', 'Machine Learning', 'C++', 'Microsoft Office', 'MySQL', 'Microsoft Excel']","['36 Entry level applicants', '20 Senior level applicants', '3 Manager level applicants', '2 Director level applicants']","['86% Applicants', '0% Applicants in the past day']",Associate,Full-time,['Online Media'],"At Scribd ( pronounced “scribbed”), we believe reading is more important than ever. Join our cast of unique characters as we build the world’s largest and most fascinating digital library: giving subscribers access to a growing collection of ebooks, audiobooks, magazines, documents, and more., , In addition to works from major publishers and top authors, we also create our own original content exclusively for Scribd users., , Our community includes over 1M subscribers in more than 190 countries. Join us in turning screen time into quality time!, , Scribd, , /skribbed/ (n)., , a tech company changing the way the world reads, a membership that gives users access to the world’s largest online library of books, audiobooks, sheet music, news, and magazines, , We value trying new things, craftsmanship, being an open book, and the people that make our team great., , Join us and build something meaningful., , About The Team, , Simply put, Core Platform is here to provide robust and foundational software, increasing operational excellence to scale apps and data at Scribd ., , Our primary customer is Scribd Engineering. We are focused on building, testing, deploying apps and infrastructure which will help other teams rapidly scale, inter-operate, integrate with real-time data, and incorporate machine learning into their products. Working with our customers in the Data Science and Content Engineering, and our peers in Internal Tools and Infrastructure teams we bring systems-level visibility and focus to our projects., , We will develop and operate standards and infrastructure for RPC, service discovery, and data ingestion., , We will be building backend systems which enable Scribd Engineering to support our product's growth on continued success. Our goal is not total architectural or design perfection, but rather choosing the right trade-offs to strike a balance between speed, quality, and cost. We will also be responsible for education and evangelism of our work within Scribd Engineering, this includes writing thorough documentation for the systems we build, hosting internal workshops, and providing implementation support to our peers across engineering., , You will, Define, build, and deploy a new, comprehensive, and cross-team data platform., Adapt existing organically-grown systems to a more thoughtful architecture for ingesting, processing, and re-incorporating content and behavioral data streams into Scribd's products., For some projects this may entail implementing new Spark-based applications, but for others it may involve updating Ruby code responsible for generating or processing inbound events from clients., , You have, Data storage expertise - Our current data stores include: MySQL, Elasticsearch, Redis, Hive, HDFS. Candidates should have a strong working understanding of building non-trivial applications utilizing at least 2+ of the given data storage technologies., Must have a strong understanding of the types of problems where relational data stores, document stores, and object stores should be used., Spark/Kafka expertise - Strong understanding of how to architect and building streaming applications and the systems which come together to support them, Experience with similar tools such as Storm, RabbitMQ, or other queueing/stream processing tools, , Ideally you have, Understanding of how to bring machine learning models from development to production, Working knowledge of how developers and data scientists develop machine learning models., , Why we work here, , Our HQ is in SF, but we have teams distributed in Toronto, Amsterdam, and remote engineering throughout the US, Health benefits: 100% employer covered Medical/Dental/Vision for regular, full-time employees, Generous PTO policy plus we close for the last week in December, 401k matching, Paid Parental leave, Monthly wellness budget, Professional development: generous annual budget for our employees to attend conferences, classes, and other events, Apple laptops and any equipment you want to customize your work station, Free Scribd membership and a yearly reading stipend!, Company events that include monthly happy hours and offsites (past events include Santa Cruz, bowling, arcades, geocaching, ropes courses, etc.), , In the meantime, check out our office and meet some of the team at https://www.scribd.com/about, , Scribd values diversity, and we make all hiring and employment decisions based on merit, qualifications, competence, talent, and contribution, not who you are by choice or circumstance. We value the people who make Scribd a great place to work and strive to create an environment where your work is supported and personhood respected.","We believe reading is more important than ever. Join our cast of unique characters as we build the world’s largest and most fascinating digital library: giving subscribers access to a growing collection of ebooks, audiobooks, magazines, documents, and more.

In addition to works from major publishers and top authors, we also create our own original content exclusively for Scribd users.

Our community includes over 1,000,000 subscribers in more than 190 countries. Join us in turning screen time into quality time!"
2020/06/08 05:32:06,https://www.linkedin.com/jobs/view/1875124050/?eBP=NotAvailableFromVoyagerAPI&recommendedFlavor=SCHOOL_RECRUIT&refId=205722bd-0386-4d74-aec5-a36e0710a3ae&trk=flagship3_search_srp_jobs,Big Data Engineer - Infrastructure and Tools,Teranet Inc.,"Toronto, CA",Posted 1 month ago,,,,,Entry level,Full-time,"['Information Technology & Services', 'Computer Software', 'Financial Services']","Big Data Engineer (with focus on infrastructure and tools), , March 16, 2020, , Teranet is seeking an experienced Big Data Engineer with focus on infrastructure and tools to maintain and support the Data Engineering technology platform. This includes the Cloudera Hadoop environment, Change Data Capture (CDC) tools including HVR and Attunity, data access and security, Visualization tools such as Tableau, as well the on-premise and cloud connectivity to our Data Lake environment and other Analytics tools required by the organization., , Key Responsibilities Include, Support, maintain & monitor Cloudera platform & infrastructure, Manage and support Cloudera data lake access requests, Manage and investigate Cloudera data lake incidents (service alerts, errors, end-user access issues), Be the primary Cloudera Support interface for Cloudera infrastructure issues, Support software updates & patching, Support Analytics server OS patching & updates (working with Infrastructure teams to coordinate backups, testing and service windows), Support & coordinate Analytics Server Firmware updates, hardware (disk) replacements with the IT Unix Support & Storage Support teams, Support Cloud DR environment and conduct regular DR and Recovery tests to ensure we are able to switch between on-prem & DR Cloud environmentsChange Data Capture (CDC), Support, Maintain & Monitor Analytics CDC Platform:Support software updates & patching (test new HVR releases in test environment & coordinate deployment to production environment)Support CDC Infrastructure (manage HVR/Attunity and Sybase/Oracle/Microsoft Staging DB server patching & upgrades)Monitor production systems and manage/address incidents related to Attunity Replicate & HVR software, Support CDC Production Rollout:Support manual DB refreshes for various applicationsSupport CDC testing (CDC Load tests with Application Teams in preparation for production rollout)Support CDC production rolloutTableau Server Infrastructure, Maintain & Monitor Tableau Server infrastructure, Manage upgrade of Tableau Server software (2-3 times per year), Coordinate Server OS patching & upgrades (testing), Coordinate Server infrastructure enhancements (memory, cpu, additional storage), Work with Analytics Architect to implement Tableau Server High-Availability (cluster), Work with Analytics Architect to design Tableau Server Business Continuity/DR environment., Support VAS, Finance, CMS Analysts in creating and deploying Tableau Data Lake Data Source connections for Tableau Dashboards, Manage and investigate incidents related to Tableau Server infrastructure, Maintain and monitor Teranet’s data lake feeds, Prepare the data views for downstream data lake consumers (e.g. Data Scientists and Analysts), Optimization of Teranet’s Big Data environment, applications and data views, Design, build and test data queries for data views and feeds for downstream data lake consumers, Design, build and integrate additional data sources into the Teranet data lake, Design, build and test analysis/data models to support downstream data lake consumers, , You Are Someone Who, , Continuously seeks to improve your knowledge of data analytics technologies and best practices, Strives to understand business drivers and strategy in order to understand business requirements, Takes a collaborative approach to assignments and works well with others, Is a good communicator with strong written and oral communication skills, Clearly documents your work so that it can be readily understood by others, Takes ownership and accountability for your assignments and responsibilities, Takes pride in delivering detail-oriented, thoughtful, thorough, and quality results, , Key Qualifications, , Bachelor’s degree in Computer, a quantitative field, or equivalent practical experience, 2-3 years of experience working with Unix/Linux, ideally with some Redhat Linux admin experience, A minimum of 1.5 years working with and administering Hadoop related technologies (HDFS, Hive, Spark, Kafka) and ideally 2-4 years of experience, Familiarity with the Cloudera Hadoop environment and in particular experience the Cloudera Management console, Software development experience with Scala, Java or Python languages as well as strong SQL development skills, Familiarity with visualization and statistical modeling tools, ideally with 1-2 years Tableau Server administration experience","Teranet is the exclusive provider of Ontario’s online property search and registration. We developed, own, and operate the Ontario Electronic Land Registration System — one of the most advanced, secure, and sophisticated land registration systems in the world. In Manitoba, Teranet owns and operates The Property Registry, providing certification of titles to land, maintains land records, and offers reliable information of financial interests in personal property to the public. Teranet is owned by OMERS Infrastructure, a leading global infrastructure investment manager and the infrastructure arm of the Ontario Municipal Employee Retirement System.

Teranet’s divisions include:

• Electronic Registration Solutions, serving government and the legal community.
• Commercial Solutions, including the Purview and GeoWarehouse solutions.
• Do Process, serving the legal community.
• *NEW Collateral Management Solutions, the largest national provider of search and lien registration services. 

See more about our recent addition of Collateral Management Solutions here: https://www.teranet.ca/commercial-solutions-blog/teranet-announcement-d-h-collateral-management-corporation/. 
 
Recent Awards 

Teranet won the 2018 Esri Special Achievement in GIS Award for its effective enterprise implementation of GIS technology to deliver better services.

The eRegistration project team for The Property Registry was nominated for a partnership award in the 20th annual Manitoba Service Excellence Awards. These awards recognize Manitoba government employees who deliver service excellence every day.

Teranet was nominated for Mortgage Awards of Excellence Product of the Year Award, which
recognizes a supplier that has put forth a unique product that has empowered the mortgage broker channel and has expanded the mortgage broker’s ability to be competitively differentiated in the marketplace.

Teranet has been recognized as one of Greater Toronto’s Top Employers for 2018. Now in its 12th year, The Greater Toronto’s Top Employer list aims to determine which employers lead their industries by offering exceptional workplaces. To see the complete 2018 Greater Toronto’s Top Employer list, please visit http://www.canadastop100.com/toronto"
2020/06/08 05:32:42,https://www.linkedin.com/jobs/view/1884509879/?eBP=NotAvailableFromVoyagerAPI&recommendedFlavor=SKILL_ASSESSMENTS&refId=205722bd-0386-4d74-aec5-a36e0710a3ae&trk=flagship3_search_srp_jobs,Data Analyst,,"Oakville, CA",Posted 1 week ago,56,"['Python (Programming Language)', 'Data Analysis', 'SQL', 'C++', 'Teamwork', 'Microsoft Excel', 'Tableau', 'Amazon Web Services (AWS)', 'Business Intelligence (BI)', 'Leadership']",['3 Entry level applicants'],"['56% Applicants', '2% Applicants in the past day']",Entry level,Full-time,"['Information Technology & Services', 'Computer Software', 'Financial Services']","Who Is Geotab, , Geotab, a global leader in IoT and connected transportation, is one of the fastest-growing technology companies in North America and a certified “Great Place to Work.” Each day, Geotab processes billions of data points from over 2 million connected vehicles, extracting actionable insights to help empower businesses to better manage their fleets. Recognized as the world’s #1 commercial telematics provider, Geotab’s solutions are used by more than 40,000 customers in over 130 countries around the globe. Geotab understands that telematics is critical to helping create safer and more sustainable drivers, businesses and communities and actively works to help businesses improve driver behavior, reduce greenhouse gas emissions and create safer roads for all. Global demand for telematics is increasing and Geotab is leading the way. Are you ready to join us? To see what it’s like to be a Geotabber, follow us @InsideGeotab on Instagram, Twitter or Facebook today!, , Who We Are Looking For, , We are looking for Data Analysts who can help us discover value out of our rich and large datasets. Our ideal team member will have the mathematical and statistical expertise you’d expect, but a natural curiosity and creative mind that’s not so easy to find. As you mine, interpret and clean our data, we will rely on you to ask questions, connect the dots and uncover opportunities that lie hidden within, all with the ultimate goal of realizing the data’s full potential. You will join a team of data specialists, but will “slice and dice” data using your own methods, creating new visions for the future. If you are a Data Analyst who knows how to extract meaning from and interpret data - we would like to hear from you!, , What Are The Details Of This Position, , As a Data Analyst you will be a crucial part of producing innovative analytics from Geotab’s big data environment. Geotab’s systems process over 40 billion data records per day from over 2 million vehicles in 100+ countries across the globe. We believe that there is collective value in the massive amount of data arising from all of our sensors across the globe. And most importantly, we believe this data can be used to improve safety, infrastructure, and productivity for our customers. You will work with our team of data scientists and engineers who have curated our data repository and have created a series of near real-time and historical datasets categorized under Weather, Urban Infrastructure and Location Analytics. You will produce insights for our partners and customers to directly benefit from the analysis and develop customer-facing products from these results. You will work closely with Data Scientists, Data Engineers, Professional Services, Data Privacy & Governance, firmware as well as all the other internal departments such as Software Development and Solutions Engineering to achieve these objectives., , Our Technology Stack, , We leverage the Google Cloud Platform (GCP) as our big-data environment. Most of our development work happens in Python, leveraging various big data and data science tools in GCP (e.g. Dataflow) as well as from the open-source community (e.g. JupyterLab)., , SQL, , Python Modules : numpy, scipy, theano, keras, pytorch, pandas, matplotlib, xgboost, scikit-learn, nltk, seaborn, networkx, osmnx, , Big Data Tools : JupyterLab, TensorFlow, Apache Spark , Beam, Dataflow, Airflow, , Google BigQuery, Kafka, Kubernetes, , Duties And Tasks/Essential Functions, Interact with Geotab’s Big Data Infrastructure on Google Bigquery using Python and SQL, Process, cleanse, and verify the integrity of data used for analysis, Examine large data sets to identify trends, develop charts, and create visual presentations to help businesses make more strategic decisions, Utilize statistical tools to interpret data sets and prepare reports that effectively communicate trends, patterns, and predictions based on relevant findings, Write SQL queries to find answers to complex business questions, Identify any data quality issues and partialities in data acquisition, Coordinate with the engineering team to gather incremental new data, Use data mining, model building, and other analytical techniques to support internal initiatives, Assist the internal technical departments by providing meaningful insight using datasets, Work with data scientists and leverage machine learning models that have been developed against Geotab’s big data environment., Experience/Skills Required:, Graduate or Postgraduate Degree in Computer Science, Electrical, or Software Engineering, Mathematics, Statistics or a related field, 3-5 years experience as a Data Analyst with proven proficiency in SQL is required, Exposure to data science tools such as Python, Pandas and NumPy is nice to have, Experience working with big data and an understanding of techniques used to extract value out of very large datasets is essential, Experience with database design and writing queries is key to be successful in this role, Familiarity with machine learning concepts and tools such as Scikit-learn and Tensorflow is an asset, Experience working with Google Compute Engine and Google Bigquery is nice to have, A keen interest to make a positive impact in the community that we live in by developing data driven smart city insights and urban analytics, What makes our staff passionate about Geotab?, , Table Tennis at the office - bring your own bat!, , Great accommodation (brand new office building, height-adjustable desks), , Light breakfast served daily, , Hot lunches or fresh sandwiches served every Friday, , Geotab-sponsored sports teams and social events, , Full medical benefits and 4% company matching RSP (full-time employees only), , Our Core Values, , Geotab is shaping the future of telematics. Using leading technology, we embrace change and challenge the status quo. To stay ahead of the curve, we keep Geotabbers energized with data bootcamps, course subsidies, Friday lunches, and more. We believe collaboration leads to innovation; our teams stretch across floors, cities and continents. All employees, from the CEO to the summer students, maintain an open-door policy. Whether we’re fine-tuning our products, or boosting our office culture, we’re building a foundation for long-term success. To us, this means safer roads, more efficient fleets and a team of dynamic Geotabbers!, , Geotab encourages applications from all qualified candidates. Geotab is committed to accommodating persons with disabilities throughout the interview, selection and employment process. If you require accommodation at any stage of the application process or want more information about our accommodation policies and practices, please contact us at (416) - 434 4309.",
2020/06/08 05:33:19,https://www.linkedin.com/jobs/view/1888489134/?eBP=CwEAAAFykzPw90DOxjDZyMghjfzhAWZY-57VNjHP-4yFrqHMZ7EbVaZAYLVZ4aLT-v0Auph9GD_b4zK8zY5N7F6GvqE381dkVf-GJnRlIXOFI_ZTM_JvvW7azggSr2ARvmfv3iuxcF19Bphv3wEiSN60MTNHQiEPET1km7hL5gB2SCtUDFDda_5Kr6LlpxrHIEH33Q3alAO3kWYyrhcbsELcXNbLdGyIL1WqSmnOhxumkPsmrT5xGWmHVCUtWMYI4-03ztoQ6mKVdo0t53NgGQuJlKDQRRJv4VsDxscskxy0lM--FXkEIuVpKJZFig_kCdt4qb6lDVVG1sktWRerJL6wmVC02vuPdlDpxaZQlm5qXL8-daTW190tEqm_urWQeGLrkWA-7tUyZ6Npt1oKCLq0wy4pZvCUxoIf2uK5a039&recommendedFlavor=COMPANY_RECRUIT&refId=205722bd-0386-4d74-aec5-a36e0710a3ae&trk=flagship3_search_srp_jobs,Senior Data Engineer,Killi,"Toronto, Ontario, Canada",Posted 6 days ago,,"['SQL', 'Python (Programming Language)', 'Java', 'Hadoop', 'Data Analysis', 'Machine Learning', 'Apache Spark', 'Amazon Web Services (AWS)', 'MySQL', 'Extract, Transform, Load (ETL)']","['50 Senior level applicants', '29 Entry level applicants', '2 Manager level applicants', '1 Director level applicant']",,Mid-Senior level,Full-time,['Information Technology & Services'],"From breaches to hacks, the world of data privacy is always an eventful one. Seriously. There is always something going on. We are right at the forefront when it comes to innovation and data privacy, and are always looking for hard-working, barrier breakers to join our team! Are you looking to pivot to the data privacy landscape? Do you want to work in a fast-paced environment with a team that is eager to hear from you?, , We are looking to add a highly motivated and results-oriented Senior Data Engineer to join our engineering team., , Who you are:, You have a passion for distributed computing, large data platforms, and event-based data, You are not fazed by complex, unstructured problems dealing with disparate data sets, You have a passion for privacy, consented data, and personal data control, You have a flair for optimization of systems running at scale, You want to do more than create a data pipeline or reports; you want to unique data sets and insights never seen before, You know how to find data, move it around, transform and fill in the gaps and implement your ideas through programming/statistical languages, You are the person who volunteers for new challenges, even in the face of uncertainty and not always being the expert, , What you will be responsible for:, Designing and developing Killi’s Data Platform which represents the first real-time, consented, multi-compliant data ingestion, analysis, and insights platform in the world, Helping build the vision, strategy for the future state of the global data market, Understanding and embracing the disparate nature of consented and public data, Scaling existing architectures while designing, adapting, and evolving for new data sets and challenges, Processing, cleansing, and verifying the integrity of the data used for analysis and for sales, , What we need from you:, An undergraduate degree in Computer Science/Engineering or equivalent from an accredited university, 3+ years in Software Development in challenging environments, Experience with Kafka/Pulsar, CDC, or other event-based processing platforms., Experience with Spark, Hadoop, or other distributed processing technologies., Experience with RedShift, EDW, and large cloud-based data storage facilities, Experience in Python and Java/Scala, Experience with various AWS technologies and platforms, An understanding of how to build scalable systems that can handle terabytes of data each day and at the same time handle millions of events in real-time, , What we would like to see as a bonus:, Experience in scaling event-driven pipelines like Kafka, Kafka Connect, and CDC, Experience with GraphDBs like AWS Neptune (preferred) or neo4j, Experience with AWS Lambda, API GW, EC2, EKS, Step-Functions, RedShift, RDS, S3, Experience with deployment tooling such as Docker, Jenkins and Kubernetes, Experience with packaging and managing data for sale – data dictionaries, DMPs, and overlays, Experience with AI and ML frameworks, Experience with Enterprise integration, architecture, and white-label or multi-tenant deployments, , What you will get from us:, Competitive compensation, Comprehensive, health, dental and vision plan, A great company culture, Be part of a diverse team, A fulfilling, challenging and flexible work experience, The opportunity for career growth, Stock Options, Wellness and Professional Development funds, , Killi welcomes and encourages applications from people with disabilities. Accommodations are available on request for candidates taking part in all aspects of the selection process.","Killi is a privacy-compliant consumer ecosystem that enables consumers to take back control of their identity from those who have been using it without their knowledge and/or consent.  
 Killi, which is available on the web and in both the iOS and Google Play stores, allows consumers to opt-in to share specific pieces of data with brands and actually earn from the use of their personal data. All Killi data is 1st party, global in nature, and is both CCPA and GDPR compliant.   Fortune 500 brands and media agencies who want to have the consumer at the base of their data strategy should contact Killi for more information on how they can become a buyer."
2020/06/08 05:33:56,https://www.linkedin.com/jobs/view/1856315168/?eBP=NotAvailableFromVoyagerAPI&recommendedFlavor=COMPANY_RECRUIT&refId=205722bd-0386-4d74-aec5-a36e0710a3ae&trk=flagship3_search_srp_jobs,Data Analyst,Procom,"Toronto, CA",Posted 1 month ago,247,"['Data Analysis', 'SQL', 'Python (Programming Language)', 'R', 'Teamwork', 'Microsoft Excel', 'Microsoft Word', 'Microsoft PowerPoint', 'Tableau', 'Microsoft Office']","['5 Entry level applicants', '2 Senior level applicants']","['247% Applicants', '5% Applicants in the past day']",Entry level,Contract,"['Information Technology & Services', 'Computer Software', 'Financial Services']","Data Analyst, , On behalf of our client in the Financial Services Sector, PROCOM is looking for a Data Analyst., , Data Analyst - Job Description, 6+ years experience, Responsible for data analysis, validation, cleansing, collection and reporting., Extract and analyze data from various sources, including databases, manual files, and external websites., Respond to data inquiries from various groups within an organization., Create and publish regularly scheduled and/or ad hoc reports as needed., Document reporting requirements and process and validate data components as required., Data Analyst - Mandatory Skills, Experience with relational databases and knowledge of query tools and/or statistical software required., Strong analytical and organizational skills required., Must possess expert level knowledge of MS Excel., Data Analyst - Assignment Start Date, ASAP - 6 months to start, , Data Analyst - Assignment Location, Toronto","Procom is one of North America’s leading staffing and contract workforce services providers. Successfully meeting the needs of Fortune 500 clients since 1978, we have 11 offices across North America, with over 10,000 skilled professionals currently on assignment.

We are an award winning staffing firm. Discover more about our Best of Staffing award and what real clients and job seekers have to say about working with Procom by checking out our client and talent ratings on ClearlyRated.

Procom has long been recognized as a market-leading source of high-performing services and solutions that transform how our clients acquire and manage the very best talent. Relying on the excellence of individuals to make a difference, we know that people matter. 

And we want to work with you."
2020/06/08 05:34:33,https://www.linkedin.com/jobs/view/1862213858/?eBP=CwEAAAFykzPw92bjBkv3RLGMz_MJ4qAI509P6B7le2uoE4BoaVaeeEvJzbfI6wmGP9mLWm_jJZn3zXe60bDsXqpmcpYXd1cInhvac5LIrmtdTVXe8-x7oh8ezaWKyqvfrBI_pIMke6t2EK61cJfZ_FEE3WXhm1_XE39nza9UdCZaGSkDufGf3X164KO4jU56ZlVn655RNz41B9SkJYcBOhMDvl70FkmuTixCVdCAFe7ujmEjUNBI3prSNt3yj-EVEkuHuJotzhFNpuc-nkJOnucwy8WW2ikb9FbpqTI1VjEX1hT3KMeNADn38oolvS1N1OXw_jMIF0oX4m-jsJ8uDZhkK2iIp1km3kEUR5f2bXLunsWGR2InX3mIoH1MHiLuEnT_jrIJvTnYB263EC8K&recommendedFlavor=COMPANY_RECRUIT&refId=205722bd-0386-4d74-aec5-a36e0710a3ae&trk=flagship3_search_srp_jobs,Distributed Computing Engineer,Huawei,"Markham, CA",Posted 1 week ago,,"['Java', 'C++', 'Python (Programming Language)', 'SQL', 'C (Programming Language)', 'JavaScript', 'Microsoft Office', 'Linux', 'MATLAB', 'Agile Methodologies']","['22 Entry level applicants', '13 Senior level applicants', '1 Manager level applicant']",,Mid-Senior level,Full-time,['Telecommunications'],"Take charge of in-depth research and prototype development in the distributed computing field, take charge of domain planning/research/prototype development, and establish differentiated competitive advantages., Solve technical problems during product implementation and apply cutting-edge technologies to improve the core competitiveness of products., Have the opportunity to participate in cutting-edge technology research and planning in the industry, work with and communicate with top distributed computing software experts around the world, and build Huawei's influence in the industry., Independently analyze and study the evolution trend of distributed computing software., , Desired Skills and Experience, Bachelor degree or above, majoring in computer science and mathematics., Have more than five years of industry experience in system level software development using the mainstream development languages such as Java, C/C++ or golang., Deeply understand data structures, algorithms, and Design Pattern., Have a proficient command of Linux system programming, network programming, and Shell programming., Have a proficient command of common software architecture modes and be proficient in using basic programming, compilation, and troubleshooting tools., Deeply understand the design and development of distributed system architecture and distributed middleware., Have experience in using and developing the big data platform or HPC middleware, such as: Hadoop/Spark/SLURM/PBS., Have good communication skills, work ethic, and a good team player., Have a passion for learning new technologies, and solving problem, Preferred qualifications:, The following experience is preferred:, Development experience of the distributed task scheduling system, such as YARN, Mesos, or SLURM., Experience with containerization (Docker, etc.) and container orchestration (Kubernetes, etc.) in deployment and operations, Experience in Distributed AI Training Framework TensorFlow Pytorch Horovod, Deep understanding of HPC and AI Convergence, Large-scale distributed system development and deployment experience","About Huawei
Huawei is a leading global provider of information and communications technology (ICT) infrastructure and smart devices. With integrated solutions across four key domains – telecom networks, IT, smart devices, and cloud services – we are committed to bringing digital to every person, home and organization for a fully connected, intelligent world.
At Huawei, innovation focuses on customer needs. We invest heavily in basic research, concentrating on technological breakthroughs that drive the world forward. We have more than 180,000 employees, and we operate in more than 170 countries and regions. Founded in 1987, Huawei is a private company fully owned by its employees."
2020/06/08 05:35:09,https://www.linkedin.com/jobs/view/1884342586/?eBP=CwEAAAFykzPw99QVdJPyPhhlgVfZMdxxs5N0kTb2BrBNqifzxdS-RCQ0Hew4nOFxixSdef-VDNTz3rW0WyQNpSSYiv4aMXrLiBOtaCxiHY63aKSyIJyI7-iWgEjdSPdlgR9LoAraWBE5TsXxWkaeOwcEXg0rtEBrRn1G88Yx1P8AhN0LpCh2Nd9TEx_Slyzcz0vRZL7xrOj3edu9Y29DCXsU0aS2kDaR4_3bt0d81Cn7BnQRnYiilo_1QcBr-7QPFXa2tvECDwoYRL_zin7q4VH1eiQvGdTqWJWZc7HWwFEv2VoSZ1FLvd6wJC6EUwd6Yd4FaVbq0DkT0ziPZPL4DaC-pDesrQNUJ4toAUBJ1MHzezzRQHyQKSXEHVc_yaODSPYtcGoXYSkPX7yyygFf&recommendedFlavor=COMPANY_RECRUIT&refId=205722bd-0386-4d74-aec5-a36e0710a3ae&trk=flagship3_search_srp_jobs,"Data Analyst, Financial Services Group",Optimus SBR,"Toronto, Ontario, Canada",Posted 1 week ago,919,"['Data Analysis', 'SQL', 'Python (Programming Language)', 'R', 'Teamwork', 'Microsoft Excel', 'Microsoft Office', 'Tableau', 'Microsoft PowerPoint', 'Microsoft Word']","['231 Senior level applicants', '224 Entry level applicants', '21 Manager level applicants', '6 Director level applicants']","['919% Applicants', '24% Applicants in the past day']",Associate,Contract,['Management Consulting'],"Who Are We?, , We built our ﬁrm to be everything typical consultancies are not. , , At Optimus SBR, we are a dynamic group of entrepreneurial thinkers who come from diverse backgrounds and fields of specialty with a passion for growing business – both ours and our clients’., , As a firm that was built on culture, we value our people and their growth, and we firmly believe that our people come first. Each of us embody the entrepreneurial spirit and have something unique to contribute to the fabric of our organization. Things like our seven employee created-and-led committees and regular celebratory events came from employees who subscribed to building a culture that puts people first. As a consulting firm, our people are our business – their happiness and engagement is directly correlated to our success., , That’s why we’ve been consistently rated one of the best places to work in North America – and are one of the fastest growing., , The Position, , As we continue to grow, we will have exciting opportunities for Data Analysts to join our Financial Services Group. , , The successful candidates will have the opportunity to collaborate, build and succeed as part of a team of high performing professionals, and the ability to share challenges and rewards that come from working with a dynamic group of entrepreneurial thinkers who come from diverse backgrounds and fields of specialty with a passion for growing businesses - both ours and our clients’., , Our Data Analysts demonstrate a high level of technical, industry knowledge and skills, working on various development projects across multiple lines of business within Banking and Financial Services., , You are ambitious, enthusiastic and adaptable with the ability to solve complex problems in a fast-paced environment. You have solid working experience and understanding of the processes within Banking and Financial Services. You are confident, ambitious and have the ability to wear multiple hats and adapt to changing needs and environments while working independently., , Responsibilities, , Key resource in collecting, organising, and interpreting data information to make it useful for a range of lines of businesses, Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality, Evolving and managing cross functional processes to ensure data integrity & compliance across numerous, diverse user communities, Champion the use of data to drive decision making and inform clients of quality standards/thresholds of acceptance for data input, Acquire data from primary or secondary data sources and maintain databases/data systems, Participate in project planning, administration and recommendation documents, Contribute to the life and culture of Optimus SBR ,  Qualifciations , , Advanced level programming ability and experience with leading data tools (i.e. SQL, SAS, Netezza, Python, Tableau, R, Hadoop, DataStage Ataccama etc.), Technical expertise regarding data models, database design development, data mining and segmentation techniques, Ability to create reports and dashboards, Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy, Prior banking and financial services experience is considered a strong asset, Prior consulting experience, is an asset, Excellent writing and communication skills. Bilingualism in English & Spanish is considered an asset., Results-oriented individual with the ability to meet aggressive timelines, Innovative and dynamic. Brings an entrepreneurial spirit to our business, Strong work ethic and someone who is energetic, enthusiastic and committed to developing their career, Required Education: Related University Degree , , What's in it for you?, , Whether you come from another consulting firm, or have experience working in industry, we welcome your unique perspectives and knowledge into our talent pool., , When you come on board, we offer a comprehensive Total Rewards Program including:, Competitive compensation, Annual performance bonuses, Flexible health benefits, Career development program, A performance culture that encourages, promotes and celebrates hard work, innovation, and overall employee contributions. One that encourages you to define your pathway, and the timeline to achieve the next level., , Beyond compensation, we also offer:, A culture of rewards and recognition, An ability to make a difference and a lasting impact, A chance to work with dynamic, collaborative, progressive, and high-performing teams, An opportunity to do challenging work and to contribute above and beyond, A flexible work/life balance, Join one of our many committees to broaden your horizon, meet new people, enhance your skills and give back to your community and workplace., , A Bold Attitude, , It means that we’re authentic. What you see is what you get. No preconceived notions. No consultant speak. No nonsense., , It means that we like to think of ourselves as the anti-consultants. We don’t assume to have prescribed answers. We make sure we’re asking the right questions, collaborate with our clients, and get results., , It means that we’re engaging. Our work may never be easy, but that doesn’t mean working with us needs to feel hard. Or onerous. Or boring. The issues we tackle may be challenging, but it’s in our DNA to make the answers inspiring., , It means we judge strategy by its execution. Ideas only make an impact if they inspire action., It means that we embrace the fog. Our processes, our frameworks, and our trust in one another inspires a sense of conﬁdence that no matter how complex the situation, we’ll ﬁnd clarity., , It means that our ambition drives us to build the kind of company we’ve always wanted to work for, and the type of company our clients have always wanted to work with., , We thank all applicants in advance for their interest however, only those candidates selected for an interview will be contacted.","Optimus SBR works with leading firms to get done what isn’t. 

We’re an independent consultancy with a long track-record of delivering game-changing results for clients in the Financial Services, Government & Broader Public Sector, Health Care, Social Sector, Transportation, Energy, Travel and other industries.

We built our firm to be everything typical consultancies are not. While our team may come from diverse backgrounds and fields of specialty, we all share a passion for growing businesses — primarily yours, and by extension, ours.

Our functional practice areas include strategy, process management, program & project management, data & analytics, human capital, change management, and learning & enablement. 

For more information, please visit our website at http://www.optimussbr.com/."
2020/06/08 05:35:46,https://www.linkedin.com/jobs/view/1822507766/?eBP=JOB_SEARCH_ORGANIC&recommendedFlavor=SKILL_ASSESSMENTS&refId=205722bd-0386-4d74-aec5-a36e0710a3ae&trk=flagship3_search_srp_jobs,Lead Data Scientist,Storm2,"Toronto, Ontario, Canada",Posted 4 days ago,679,"['Python (Programming Language)', 'Machine Learning', 'SQL', 'Data Analysis', 'R', 'Data Science', 'C++', 'Microsoft Excel', 'Microsoft Office', 'MATLAB']","['257 Senior level applicants', '222 Entry level applicants', '35 Manager level applicants', '14 Director level applicants']","['679% Applicants', '7% Applicants in the past day']",Mid-Senior level,Full-time,['Information Technology & Services'],"Lead Data Scientist (Toronto):,   A multi award-winning InsurTech based in Toronto, is looking for a talented Senior Data Scientist to join their team. Awarded for their excellent working environment and company policies, they are offering challenging projects and development opportunities, paired with a comprehensive financial rewards program.,   What will you be doing?, Developing state-of-the-art solutions for trend recognition using ML and advanced statistical skills, Maintaining current data mining tools and platforms used throughout the business, Working with other departments to promote the adoption of analytical principles within the organization, Developing new approaches and trends and implementing in new solutions,   What skills are they looking for?, MSc./PhD. in Computer Science or related field, 5+ years’ experience in the implementation of data and text mining tools and advanced statistics, Multi-platform experience with open-source frameworks (R, Python, GitHub…), Deep understanding in either computer image analysis, NLP or AI,   Think you could be who they are looking for? Apply directly below, or drop @Olivia Evenden a message on Linkedin to find out more!",A multi award-winning InsurTech based in Toronto
2020/06/08 05:36:23,https://www.linkedin.com/jobs/view/1848816344/?eBP=JOB_SEARCH_ORGANIC&recommendedFlavor=SKILL_ASSESSMENTS&refId=205722bd-0386-4d74-aec5-a36e0710a3ae&trk=flagship3_search_srp_jobs,Data Analyst,UST Global,"North York, CA",Posted 2 weeks ago,344,"['SQL', 'Data Analysis', 'Python (Programming Language)', 'R', 'Machine Learning', 'Microsoft Excel', 'Microsoft Office', 'Tableau', 'Data Visualization', 'Microsoft PowerPoint']","['87 Entry level applicants', '71 Senior level applicants', '4 Director level applicants', '2 Manager level applicants']","['344% Applicants', '8% Applicants in the past day']",Entry level,Full-time,"['Information Technology & Services', 'Computer Software', 'Financial Services']","Data Scientist, , Description, , UST Global is looking for Data Scientist to build end to end business solutions and to work with one of the leading financial services organization in US and Canada. The ideal candidate must possess strong background on frontend and backend development QA technologies. The candidate must possess excellent written and verbal communication skills with the ability to collaborate effectively with domain experts and technical experts in the team., , Job Description, Credit scorecard model development experience in financial services industry, Experience in risk model oversight, assessment, and management, Data extraction and manipulation experience, Proficient in Python, SQL, SAS, able to automate through macros in each language, 7 10 years experience in model development and or assessment, Preferred Skills, Agile project experience or experience with large scale analytical projects, Data QC proficiency. Have dealt with and resolved data quality issues, Technical writing skills, experience in specification documentation of models and attributes, Proficiency in MS Office VBA to automate high volume internal and customer facing documentation, Credit score migration experience preferred, Client facing skills, bilingual, Bachelor, , UST Global is a private high growth organization headquartered in Orange County California and is a leading provider of Advanced Computing and Digital Services for Global 1000 companies worldwide. Our next-generation digital consultancy is the ideal place for you to grow your career. Are you up for the challenge? Read on!, , Primary Location, , CA-CA-North York, , Organization, , UST CAN, , Employment Type, , Regular Employee, , Job Type, , Full-time, , Job Level, , Day Job, , Job Posting, , May 21, 2020, 3:40:11 PM","UST Global is a leading digital technology services company that provides powerful solutions for Global 1000 companies. UST Global's mission is to lead companies through critical digital transformations to drive higher business value. UST Global specializes in six next generation digital services – design, cyber security, mobile, social, analytics and cloud. Powered by the mantra 'fewer clients, more attention', UST Global strives for excellence in providing their clients high quality services and a commitment to long-term success. Headquartered in Aliso Viejo, California, UST Global has over 20,000 associates; operating in 25 countries across four continents.
For more information, please visit www.ust-global.com"
2020/06/08 05:37:00,https://www.linkedin.com/jobs/view/1881210124/?eBP=CwEAAAFykzPw95RUIzStc-ZT_vD2-D1pG48OR-se1LhEK0ojKs9Fi5_wF9jdEwvi-H9izAyExVg-S_XIl754527RTQb3BsqR4FiwOLNhJl4wmC5gtcT-Ikq8oBOOIQkH3gAvQnKKFIVmZqDfAGL1ni1pXlVCyQCxApIsAN0uxxLiLh-nhygDoz77mpkwLaIXe2l6f2wSszhmp_NqgVbAVE6MtdRF1s4P_Q2Wbgi0BOp8v_CFyYsCo5lR0SriiFxeeL62U0v6smFUOE_5aOt0OpmbqjYehfi5ga7V275hGCzO3QQP3gEoqhudnHoAgLSEEXbrUWTCAKrgBF2wGueM3jh0QelyXC1Im9RMnocN-kwI6eneXYeKa7Bw9ah0-Mg9cRdvJwNTy9M1Dl4HJ0Yj&recommendedFlavor=SKILL_ASSESSMENTS&refId=205722bd-0386-4d74-aec5-a36e0710a3ae&trk=flagship3_search_srp_jobs,Data Specialist Advisor,Desjardins,"Toronto, CA",Posted 1 week ago,69,"['SQL', 'Data Analysis', 'Python (Programming Language)', 'R', 'Microsoft Excel', 'Microsoft Office', 'Tableau', 'Business Intelligence (BI)', 'Data Visualization', 'Project Management']","['21 Senior level applicants', '16 Entry level applicants', '5 Manager level applicants', '1 Director level applicant']","['69% Applicants', '2% Applicants in the past day']",,Full-time,"['Information Technology & Services', 'Computer Software', 'Insurance']","Desjardins Group is the largest cooperative financial group in Canada, and one of the largest employers in the country. It offers a full range of financial products and services and is home to a wealth of expertise in property and casualty insurance, life and health insurance, wealth management, services for businesses of all sizes, securities brokerage, asset management, venture capital, and secure, leading-edge virtual access methods., , Job Level, AC-09, , As an actuarial and statistical advisor, you help ensure profitability and balanced risk-return ratios for products and services. You also establish reserves, produce statistical models that inform decision-making, and analyze problems and business opportunities for the organization’s actuarial initiatives., , You advise and assist clients and partners as part of intervention and development initiatives. You recommend solutions to improve or optimize standards, policies and programs. Your projects and initiatives require extensive knowledge of your line of work., , You prepare recommendations, solutions and action plans based on the organization’s objectives and priorities. You help solve complex problems using your analytical skills and extensive knowledge of your line of business. Coordination is critical, so you frequently interact with stakeholders working in other fields. Interpersonal savvy is therefore essential., , #Teaser, , Do you live and breathe data? Are you passionate for big data, little data, muddled data and all data in between? Do you want to design, implement and populate data models that make it possible to automate our data analytics value chain? Come be at the heart of a data driven organisation by joining a critical service for the proper functioning and operation of a top Canadian insurer. Come innovate and change the world of insurance with us! A world in constant change and in continuous need of data innovation. Be part of the journey!, , We don’t offer you a job, we offer you job satisfaction! #Desjardinsdifference, , #Team, , The Modeling and Best Practices team is looking for a candidate to join us in the unique role as a Data Specialist Advisor. Are you interested in working on a multi-disciplinary team with people from various backgrounds (statisticians, actuaries, data scientists) in a motivating environment in which we focus on developing our people? Does the idea of leveraging your strengths while being challenged to explore data analytics and predictive analytics align with your vision and growth? Then you may be the one we are looking for!, , #What you will do, , As a Data Specialist Advisor for the Modeling and Best Practices team, you will be responsible for:, Developing and maintaining data models for use in advanced analytics., Advising on potential solutions for various data management-related issues., Analyze data and data structures, as well as the design and build of all forms of database schemas (relational, OLAP, Big Data etc.) to support a wide range of strategies for secure data acquisition, data cleansing and blending, data storage, analysis and modeling., Responsible for communication of data management needs and process steps in non-technical language., Responsible for communication of data engineering steps required to industrialize an advanced analytics model in technical language., Developing or improving existing processes., Keeping pace with new advancement in data management and advanced analytics, intent on applying them to your work., Coaching or more junior staff to help disseminate expertise., , #What you bring to the table, A bachelor degree in Statistics, Mathematics, Computer Science or Actuarial Sciences., Minimum of 3 years working across BIG or complex data sets in a statistical / analytical role: academic work experience may be considered., Experience with open source cloud-based platforms, Microsoft Azure, or any other public / private cloud based platforms, Expertise in working with structured data; apply methods, technologies and techniques that address data architecture, integration and governance of data, Experience in database concepts, data modelling; data integration including design and architecture, Knowledge of master data management principles and experience with data catalog applications, Expertise in working with unstructured data; ability to apply semantic correlation, ontology and text analytics techniques and systems to analyze non-structured data and identify critical insights for overall business analytics across various domains, Possess solid skills in SAS, SQL, R, and Python (Hadoop, Java, Scala and C++ knowledge / experience is an asset)., Provide thought-leadership and dependable execution on diverse projects, Relevant P&C insurance experience is an asset., English proficiency, both oral and written (for postings in Quebec). Bilingualism is an asset., Required qualities: client-focused, adaptable, team-oriented, curious, can-do attitude, good synthesizing, communication and stakeholder management skills., , #What we offer, Training and development opportunities to grow your career with one of Canada’s top 100 employers., Flexible work options and paid time off to support your personal and family needs., A holistic approach to your well-being, with physical and mental health programs and a supportive workplace culture., A comprehensive compensation package, including competitive salary, bonus, defined benefit pension plan and benefits., Fitness reimbursement program., Discounts on automobile and home insurance premiums., Full reimbursement of Insurance Institute of Canada courses., Free second-language course in the workplace., Reimbursement of job-related continuing education costs., Time off for study days for actuarial examinations., , Desjardins Cross-sector Skills, , Action oriented, Collaborates, Customer Focus, Innovation, , Key competencies for the job, Action oriented, Business insight, Collaborates, Customer Focus, Innovation, Interpersonal Savvy, , Work Location, 95 St-Clair Avenue West Toronto, , Trade Union, Non Syndiqué, , Unposting Date, 2020-06-25, , Job Family, Actuarial Services (FG)","Desjardins Group is the leading cooperative financial group in Canada and the fifth largest cooperative financial group in the world with assets of $227 billion. It has been rated one of Canada’s top 100 employers by Mediacorp Canada. To meet the diverse needs of its members and clients, Desjardins offers a full range of products and services to individuals and businesses through its extensive distribution network, online platforms and subsidiaries across Canada. The group has one of the highest capital ratios and credit ratings in the industry. It is considered as the fourth safest and strongest bank in North America according to Global Finance magazine 
and the first according to Bloomberg News."
2020/06/08 05:37:37,https://www.linkedin.com/jobs/view/1859114738/?eBP=CwEAAAFykzPw9wgjv2_7pnSvye9bB1Ovp9OkJzeXYoGxH5-VEFbrSIrJQN1sV1NLSyggfJvRA-blQQvkurFWYZkUHxwjU2ehqg8BU_qMdv-dDq52ofUTgTHk0W56xhfMa5rtKD4pCjwR_OGswKNqDYBhA2HJr2P_Vq0531QJd1AGpJ3b8_9BEya_mzSgYitrmTbYer9plwVygXSydkgQvgztjmIkfJuj5tQ2OdxwpBAix2UuK5ZPjMbi0l9EPGioZXQsloDmqST7MxgqD19TGKQXTt-IFpAq-Rdh1daMgKf1xTBBcnlo7usBM4JNDN5Gtb42FhUqn0feBbT4E5PweE3cpMGRg38g6DTc9DNc8aJfW_vK3xI7i8mc1wptuk9pMTUjcy7zCTKYjCY_vQ&recommendedFlavor=SKILL_ASSESSMENTS&refId=205722bd-0386-4d74-aec5-a36e0710a3ae&trk=flagship3_search_srp_jobs,MONITORING PLATFORM ENGINEER,Allstate Canada,"Markham, CA",Posted 3 weeks ago,36,"['SQL', 'Python (Programming Language)', 'ITIL', 'Linux', 'Unix', 'IT Service Management', 'Microsoft Office', 'MySQL', 'Microsoft SQL Server', 'Shell Scripting']","['14 Senior level applicants', '9 Entry level applicants', '1 Director level applicant', '1 Manager level applicant']","['36% Applicants', '1% Applicant in the past day']",,Full-time,"['Consumer Services', 'Financial Services', 'Insurance']","Considering the current events, Allstate will be conducting virtual interviews and has made arrangements for new hires to work remotely till its deemed safe to return to office, , Through our core values, Opportunity, Flexibility, Community, Diversity and Family, we have worked hard to develop and nurture a culture where employees feel valued, experience personal growth, have career options and truly enjoy the work they do., , Benefits To Joining Allstate, Complete Group Benefits Program customizable to your needs, Strong Brand Recognition (listed as best Employer with Kincentric since 2012)., Working within the community and giving back!, Opportunity for career development and growth., We work a 37.5 hour work week and we are proud to offer work from home opportunities once you have demonstrated knowledge and the required skills., , , Our team is growing and we are actively looking to hire an Enterprise Monitoring platform engineer to work with Monitoring Team. This is a perfect opportunity for professionals with minimum 8 years’ experience who wants to gain hands-on experience in various monitoring platforms and work with experienced architects. He will be working closely with Application, Infrastructure and architect team in Allstate Canada Group to Setup monitoring system., , Enterprise Monitoring Platform Engineer is a key member of Monitoring team that manages the Application, Event Aggregation / Correlation and Logging monitoring platforms which focuses on monitoring application availability and capacity., , Work on the Monitoring tools such as Dynatrace One Agent, event aggregation tools and logging tools like Splunk, , Job Qualification Criteria, Minimum 8 years overall experience in Information Technology (IT)., Experience in Application and Infrastructure monitoring tools., Must have experience with monitoring tools like Dynatrace AppMon/Dynatrace One Agent and/or SolarWinds (SAM) etc., Experience in Splunk & related technologies for creation of dashboards, alerts, reports, schedule searches, forwarder deployments, etc., Experience in Perl/Shell scripts to build customized monitoring and interfaces with other tools., Automation using Python, Shell scripts and PowerShell, Minimum 5 years’ experience in a Monitoring Engineering related role, Strong ability to monitor & diagnose IT infrastructure, application services, server, network alerts, events or issues., Able to collate and interpret data from various monitoring sources and perform log analysis., Should have experience in troubleshooting 3 tier architecture environment, Should have good troubleshooting skills for any web-based applications and databases., Experience on data analytics tools will be added advantage, Experience of analyzing system and network performance using monitoring tools and historical / real time data., Good knowledge on Application and database server, Good Linux experience, Good to have experience on Kafka., Knowledge of IT operations, responsibilities, workflow processes and procedures, ITIL framework, Self-motivated, professional attitude and works well under pressure., Strong attention to detail and follow-through, Quick learner on a wide range of issues, including identifying improvement opportunities, Excellent problem-solving skills, and results-oriented attitude. Excellent team skills, including strong work ethic., Ability to assess faults, prioritizes, respond and escalate accordingly, Strong organizational, interpersonal and communication skills., Willingness to learn any new tool/technology with changing business needs/Priorities, , , Job Responsibilities, Work on the Monitoring tools such as AppMon, Dynatrace, event aggregation tools/ logging tools like SolarWinds and Splunk., Implement Self-healing scripts for monitoring multiple monitoring tools and recover them Develop monitoring plugins, scripts for automation and custom dashboards., Analyze AppMon/Dynatrace/Splunk analytical data., Middleware technologies, Automate manual monitoring component across application., Discover automation opportunities in depth in collaboration with architects and development team., Should be aware of basic file manipulation, file system traversing., Proactive monitoring of IT infrastructure and application/services alerts via monitoring tool and Email., Impact and Severity Assessments of service failures., End-to-End ownership of tickets created via alerts, accurately recording progress and escalations on ticketing systems., 1st level of investigation/diagnosis., Fast and effective response to service failure Alerts and Notifications., On time escalations and Follow up with the IT / Application Support team on pending high priority alerts according to incident management process., Work with teams across the globe, , , Work Timings, Should be Flexible for work timings if need arises., Willingness to be on call if any issues comes up work in, Working shift 9 AM to 5 PM EST., , Allstate Canada Group has policies and practices that provide workplace accommodations. If you require accommodation please let us know and we will work with you to meet your needs., , Allstate Insurance Company of Canada is one of the country's leading producers and distributors of home and auto insurance products, serving Canadians since 1953. The company strives to keep its customers in ""Good Hands®"" as well as its employees, and is proud to be named a Best Employer in Canada. Allstate Canada is committed to making a positive difference in the communities in which it operates and has partnered with organizations such as MADD Canada, United Way and Junior Achievement. To learn more about Allstate Canada, visit www.allstate.ca. For safety tips and advice, visit www.goodhandsadvice.ca., , For the eighth consecutive year, we are proud to be recognized as a #Kincentric Best Employer!","Allstate Canada is one of the country’s leading producers and distributors of home and auto insurance products, serving Canadians since 1953. The company strives to keep its customers in ""Good Hands®"" as well as its employees, and has been listed on Aon's Best Employers in Canada list for six years in a row, and has earned Platinum status since this distinction was introduced.

Allstate Canada is committed to making a positive difference in the communities in which it operates and has partnered with organizations such as Mothers Against Drunk Driving (MADD Canada), Crime Stoppers, United Way, and Junior Achievement. 

To learn more, visit allstate.ca, the Good Hands blog (goodhandsadvice.ca), or Allstate Canada’s social media pages.

Follow @AllstateCanada on Facebook, Instagram, and Twitter for more updates."
2020/06/08 05:38:13,https://www.linkedin.com/jobs/view/1883137246/?eBP=NotAvailableFromVoyagerAPI&recommendedFlavor=SKILL_ASSESSMENTS&refId=205722bd-0386-4d74-aec5-a36e0710a3ae&trk=flagship3_search_srp_jobs,Data Scientist,International Financial Company,"Toronto, CA",Posted 1 week ago,75,"['Python (Programming Language)', 'SQL', 'Machine Learning', 'C++', 'Data Analysis', 'MATLAB', 'Research', 'Deep Learning', 'Git', 'Microsoft Office']","['6 Entry level applicants', '3 Senior level applicants']","['75% Applicants', '1% Applicant in the past day']",Entry level,Full-time,"['Information Technology & Services', 'Computer Software', 'Financial Services']","Salary Mid-Point: $90,000, , Location: Toronto ON, , Job Type: Permanent, , Position Title: Data Scientist, , Position Type:Permanent, , Location:Toronto, , Our client is looking for a Data Scientist, as a Data Scientist, you will be responsible for leading, designing and developing data solutions and layering it with data science using the new gen tools and technology to support both internal and external client facing business processes. In this role the individual will work with different parts of the organization to understand the data needs and accordingly build the design and implement efficient, reliable, scalable, secure reports and analysis using big data technologies in Cloud Infrastructure to meet the business needs while complying with enterprise governed standards. This role will also be responsible for creating and building custom, re-usable interactive web based data visualizations based on statistical and mathematical modeling and data analysis to be used to solve a variety of problems related to data reporting., , To be successful in the role strong knowledge of computer applications, database management and data science concepts and tools are required. This role will also dedicate time and effort to research and pilot new techniques that will help serve our customers of data more efficiently, , You Will Be Accountable For, , Build and support data and machine learning models related to varying business applications, customer, product, sales, etc., , Research, design, and develop dashboards and web applications using data and predictions, , Partner with Data Engineering team to determine the best architecture to develop data science applications, , Coordinate with different functional teams to implement and automate models and measure outcome and develop processes and tools to provide data and predictions to the end users, , Programming and support in writing production ready data science scripts/applications, , Your Experience Includes, , Masters in Computer Science, Mathematics, Engineering, , 5+ years of experience in building machine learning / data science solutions, , Must have 2+ years of experience working with cloud-based services and systems Microsoft Azure, Apache Spark, Databricks, , Familiarity with relational or NoSQL database development, , Data Visualisation (Plotly ,Tableau, D3.js, GGplot), , Programming languages and frameworks – Python, Scala, Spark, SQL, Java, JavaScript, JQuery, HTML, CSS, Node.js, , If you are interested in this opportunity, kindly send your resumes in MS Word format to click apply today!",
2020/06/08 05:38:50,https://www.linkedin.com/jobs/view/1880107201/?alternateChannel=search&refId=205722bd-0386-4d74-aec5-a36e0710a3ae&trk=flagship3_search_srp_jobs,Big Data Engineer,Accenture,"Toronto, CA",Posted 1 week ago,56,"['Python (Programming Language)', 'SQL', 'Java', 'Hadoop', 'Data Analysis', 'Big Data', 'C++', 'Machine Learning', 'Apache Spark', 'C (Programming Language)']","['17 Senior level applicants', '17 Entry level applicants', '1 VP level applicant', '1 Manager level applicant']","['56% Applicants', '1% Applicant in the past day']",Mid-Senior level,Full-time,"['Information Technology & Services', 'Computer Software', 'Internet']","Big Data Engineer, , Location: Toronto, Montreal, Ottawa, , We Are:, , Applied Intelligence, the people who love using data to tell a story. We’re also the world’s largest team of data scientists, data engineers, and experts in machine learning and AI. A great day for us? Solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. We believe a mix of data, analytics, automation, and responsible AI can do almost anything—spark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. Want to join our crew of sharp analytical minds? Visit us here to find out more about Applied Intelligence., , You Are:, , A Big Data consulting pro—someone who thrives in a team setting where you can use your creative and analytical prowess to obliterate problems. You’re passionate about digital technology, and you take pride in making a tangible difference. You have communication and people skills in spades, along with strong leadership chops. Complex issues don’t faze you thanks to your razor-sharp critical thinking skills. Working in an information systems environment makes you more than happy., , The Work:, , Data and Analytics professionals define strategies, develop and deliver solutions that enable the collection, processing and management of information from one or more sources, and the subsequent delivery of information to audiences in support of key business processes., , Big Data professionals use Big Data methodologies, solutions and tools to help organizations optimize their business performance by managing, sorting and filtering volumes of data as well as extracting meaningful value from these large volumes of data., , A professional at this position level within Accenture has the following responsibilities:, Design and build robust data pipelines using scalable tools and techniques (yes, we’re talking big data) to produce high quality data structures, Implement quicker data processing methods and integrate complex business logic compatible with daily or real-time/streaming frameworks, Increase automation and scaling of complex data sets based on the customer’s analytic use case, such as structured data delivery for business analysis, daily extraction of mission enabling data for data mining/exploration, and transforming data for applied intelligence to power impactful data visualizations, , Here’s What You Need:, , Qualifications:, Minimum 3years of designing, building and operationalizing large scale enterprise data solutions and applications using one or more of Azure / AWS / GCP data and analytics services in combination with custom solutions - Spark, Azure Data Lake, HDInsights, SQL DW, DocumentDB, Search, Elastic Pool etc., Minimum 3years of hands-on experience analyzing, re-architecting and re-platforming on-premise data warehouses to data platforms on Azure / AWS / GCP using AZURE/customservices., Minimum3 years of designing and building production data pipelines from ingestion to consumption within a hybrid big data architecture, using Java, Python, Scala etc., High emphasis on consulting/client facing experience, this is a must have., Minimum 3 years of architecting and implementing next generation data and analytics platforms on Azure / AWS / GCP., Minimum 3 years of designing and implementing data engineering, ingestion and curation functions on Azure / AWS / GCP using AZURE native or custom programming., Minimum 3years experience in performing detail assessments of current state data platforms and creating an appropriate transition path to Azure / AWS / GCP., Hands-on Azure / AWS / GCP experience with a minimum of 1 solutions designed and implemented at production scale., Candidate should be eligible for Reliability/Government Secret Clearance (Spent at least the past 5 years in Canada as a permanent Resident or a Canadian Citizen), , Bonus Points if:, Bachelor's degree in Computer Science, Engineering, Technical Science or 3+ years of technical architecture and build experience with large scale solutions., Minimum 3 years of experience in architecting large-scale data solutions, performing architectural assessments, crafting architectural options and analysis, finalizing preferred solution alternative working with IT and Business stakeholders., 3 years of hands-on experience designing and implementing data ingestion solutions on Azure / AWS / GCP using custom approaches., 3 years of hands-on experience architecting and designing data lakes on Azure / AWS / GCP cloud serving analytics and BI application integrations., 3 years of experience in designing and optimizing data models on Azure / AWS / GCP, 3 years of experience integrating AZURE security services with Azure / AWS / GCP data services for building secure data solutions., Minimum 3years experience introducing and operationalizing self-service data preparation tools (e.g. Trifacta, Paxata) on AZURE., Minimum 3 years of architecting and operating large production Hadoop/NoSQL clusters on premise or using Cloud services., Minimum 3 years architecting and implementing metadata management on Azure / AWS / GCP., Architecting and implementing data governance and security for data platforms on Azure / AWS / GCP., Designing operations architecture and conducting performance engineering for large scale data lakes a production environment., Craft and lead client design workshops and provide tradeoffs and recommendations towards building a solutions., Author blog entries and whitepapers on AZURE data solutions, architecture and strategic topics., , Accenture Overview, , We are a global collective of innovators applying the New every day to improve the way the world works and lives. Help us show the world what’s possible as you partner with clients to unlock hidden value and deliver innovative solutions. Empowered with innovative tools, continuous learning and a global community of diverse talent and perspectives, we drive success in a new business architecture that disrupts conventional practices. Our expertise spans 40+ industries across 120+ countries and impacts millions of lives every day. We turn ideas into reality., , Important information, , To learn more about Accenture, and how you will be challenged and inspired from Day 1, please visit our website at accenture.ca/careers.https://accntu.re/2Hcjdtn, , It is currently our objective to assign our people to work near where they live. However, given the nature of our business and our need to serve our clients our employees must be available to travel when needed., , Accenture does not discriminate on the basis of race, religion, color, sex, age, non-disqualifying physical or mental disability, national origin, sexual orientation, gender identity or expression, or any other basis covered by local law. Accenture is committed to providing employment opportunities to current or former members of the armed forces., , We are committed to employment equity. We encourage all people, including women, visible minorities, persons with disabilities and persons of aboriginal descent to apply., , Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Combining unmatched experience and specialized skills across more than 40 industries and all business functions — underpinned by the world’s largest delivery network — Accenture works at the intersection of business and technology to help clients improve their performance and create sustainable value for their stakeholders. With 469,000 people serving clients in more than 120 countries, Accenture drives innovation to improve the way the world works and lives. Visit us at www.accenture.com.","Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries – powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 505,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises."
2020/06/08 05:39:28,https://www.linkedin.com/jobs/view/1880107201/?eBP=CwEAAAFykzPw9oZCognIwlK9_-mLqL9kVvu0AGwbFs7LivpAHPZMwJ09DKi5LFla7RMbxTp5hCZCCtq1jBTMFfdE7_g7lKJa6GjwryylRpJi3RWBInP_J3HxmsmfLdKPAA2gopv-m5IAMgUmLqy5eJ8KQQ0KKj0QtrLTzUCcMJJbt2CjHR8lQFfVEtgj8M9FAj0lE4TOYRGvwOmwqkQMFEpkhWaOneibJTY3hC_HdvaKStfXkHl8GxDF86mqC9nkmvF7unX68J1M0aH2jVnNtOTlk_X7nOosE4OA5Evg_6Mh10ssCXqsSz8qGfEEcgPXNxxDEzGJXXPmWY_iq-YJaRQAAnL66sUavsE6rWbedKNDbb4af6bR3Oddpl3vR_OV1WFXIXYhkhOYydQzfQrq&recommendedFlavor=IN_NETWORK&refId=205722bd-0386-4d74-aec5-a36e0710a3ae&trk=flagship3_search_srp_jobs,Big Data Engineer,Accenture,"Toronto, CA",Posted 1 week ago,56,"['Python (Programming Language)', 'SQL', 'Java', 'Hadoop', 'Data Analysis', 'Big Data', 'C++', 'Machine Learning', 'Apache Spark', 'C (Programming Language)']","['17 Senior level applicants', '17 Entry level applicants', '1 VP level applicant', '1 Manager level applicant']","['56% Applicants', '1% Applicant in the past day']",Mid-Senior level,Full-time,"['Information Technology & Services', 'Computer Software', 'Internet']","Big Data Engineer, , Location: Toronto, Montreal, Ottawa, , We Are:, , Applied Intelligence, the people who love using data to tell a story. We’re also the world’s largest team of data scientists, data engineers, and experts in machine learning and AI. A great day for us? Solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. We believe a mix of data, analytics, automation, and responsible AI can do almost anything—spark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. Want to join our crew of sharp analytical minds? Visit us here to find out more about Applied Intelligence., , You Are:, , A Big Data consulting pro—someone who thrives in a team setting where you can use your creative and analytical prowess to obliterate problems. You’re passionate about digital technology, and you take pride in making a tangible difference. You have communication and people skills in spades, along with strong leadership chops. Complex issues don’t faze you thanks to your razor-sharp critical thinking skills. Working in an information systems environment makes you more than happy., , The Work:, , Data and Analytics professionals define strategies, develop and deliver solutions that enable the collection, processing and management of information from one or more sources, and the subsequent delivery of information to audiences in support of key business processes., , Big Data professionals use Big Data methodologies, solutions and tools to help organizations optimize their business performance by managing, sorting and filtering volumes of data as well as extracting meaningful value from these large volumes of data., , A professional at this position level within Accenture has the following responsibilities:, Design and build robust data pipelines using scalable tools and techniques (yes, we’re talking big data) to produce high quality data structures, Implement quicker data processing methods and integrate complex business logic compatible with daily or real-time/streaming frameworks, Increase automation and scaling of complex data sets based on the customer’s analytic use case, such as structured data delivery for business analysis, daily extraction of mission enabling data for data mining/exploration, and transforming data for applied intelligence to power impactful data visualizations, , Here’s What You Need:, , Qualifications:, Minimum 3years of designing, building and operationalizing large scale enterprise data solutions and applications using one or more of Azure / AWS / GCP data and analytics services in combination with custom solutions - Spark, Azure Data Lake, HDInsights, SQL DW, DocumentDB, Search, Elastic Pool etc., Minimum 3years of hands-on experience analyzing, re-architecting and re-platforming on-premise data warehouses to data platforms on Azure / AWS / GCP using AZURE/customservices., Minimum3 years of designing and building production data pipelines from ingestion to consumption within a hybrid big data architecture, using Java, Python, Scala etc., High emphasis on consulting/client facing experience, this is a must have., Minimum 3 years of architecting and implementing next generation data and analytics platforms on Azure / AWS / GCP., Minimum 3 years of designing and implementing data engineering, ingestion and curation functions on Azure / AWS / GCP using AZURE native or custom programming., Minimum 3years experience in performing detail assessments of current state data platforms and creating an appropriate transition path to Azure / AWS / GCP., Hands-on Azure / AWS / GCP experience with a minimum of 1 solutions designed and implemented at production scale., Candidate should be eligible for Reliability/Government Secret Clearance (Spent at least the past 5 years in Canada as a permanent Resident or a Canadian Citizen), , Bonus Points if:, Bachelor's degree in Computer Science, Engineering, Technical Science or 3+ years of technical architecture and build experience with large scale solutions., Minimum 3 years of experience in architecting large-scale data solutions, performing architectural assessments, crafting architectural options and analysis, finalizing preferred solution alternative working with IT and Business stakeholders., 3 years of hands-on experience designing and implementing data ingestion solutions on Azure / AWS / GCP using custom approaches., 3 years of hands-on experience architecting and designing data lakes on Azure / AWS / GCP cloud serving analytics and BI application integrations., 3 years of experience in designing and optimizing data models on Azure / AWS / GCP, 3 years of experience integrating AZURE security services with Azure / AWS / GCP data services for building secure data solutions., Minimum 3years experience introducing and operationalizing self-service data preparation tools (e.g. Trifacta, Paxata) on AZURE., Minimum 3 years of architecting and operating large production Hadoop/NoSQL clusters on premise or using Cloud services., Minimum 3 years architecting and implementing metadata management on Azure / AWS / GCP., Architecting and implementing data governance and security for data platforms on Azure / AWS / GCP., Designing operations architecture and conducting performance engineering for large scale data lakes a production environment., Craft and lead client design workshops and provide tradeoffs and recommendations towards building a solutions., Author blog entries and whitepapers on AZURE data solutions, architecture and strategic topics., , Accenture Overview, , We are a global collective of innovators applying the New every day to improve the way the world works and lives. Help us show the world what’s possible as you partner with clients to unlock hidden value and deliver innovative solutions. Empowered with innovative tools, continuous learning and a global community of diverse talent and perspectives, we drive success in a new business architecture that disrupts conventional practices. Our expertise spans 40+ industries across 120+ countries and impacts millions of lives every day. We turn ideas into reality., , Important information, , To learn more about Accenture, and how you will be challenged and inspired from Day 1, please visit our website at accenture.ca/careers.https://accntu.re/2Hcjdtn, , It is currently our objective to assign our people to work near where they live. However, given the nature of our business and our need to serve our clients our employees must be available to travel when needed., , Accenture does not discriminate on the basis of race, religion, color, sex, age, non-disqualifying physical or mental disability, national origin, sexual orientation, gender identity or expression, or any other basis covered by local law. Accenture is committed to providing employment opportunities to current or former members of the armed forces., , We are committed to employment equity. We encourage all people, including women, visible minorities, persons with disabilities and persons of aboriginal descent to apply., , Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Combining unmatched experience and specialized skills across more than 40 industries and all business functions — underpinned by the world’s largest delivery network — Accenture works at the intersection of business and technology to help clients improve their performance and create sustainable value for their stakeholders. With 469,000 people serving clients in more than 120 countries, Accenture drives innovation to improve the way the world works and lives. Visit us at www.accenture.com.","Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialized capabilities across more than 40 industries – powered by the world’s largest network of Advanced Technology and Intelligent Operations centers. With 505,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises."
2020/06/08 05:41:01,https://www.linkedin.com/jobs/view/1881210124/?alternateChannel=search&refId=e98f7dc7-ff97-42d3-afb7-354d4b7be601&trk=flagship3_search_srp_jobs,Data Specialist Advisor,Desjardins,"Toronto, CA",Posted 1 week ago,69,"['SQL', 'Data Analysis', 'Python (Programming Language)', 'R', 'Microsoft Excel', 'Microsoft Office', 'Tableau', 'Business Intelligence (BI)', 'Data Visualization', 'Project Management']","['21 Senior level applicants', '16 Entry level applicants', '5 Manager level applicants', '1 Director level applicant']","['69% Applicants', '2% Applicants in the past day']",,Full-time,"['Information Technology & Services', 'Computer Software', 'Insurance']","Desjardins Group is the largest cooperative financial group in Canada, and one of the largest employers in the country. It offers a full range of financial products and services and is home to a wealth of expertise in property and casualty insurance, life and health insurance, wealth management, services for businesses of all sizes, securities brokerage, asset management, venture capital, and secure, leading-edge virtual access methods., , Job Level, AC-09, , As an actuarial and statistical advisor, you help ensure profitability and balanced risk-return ratios for products and services. You also establish reserves, produce statistical models that inform decision-making, and analyze problems and business opportunities for the organization’s actuarial initiatives., , You advise and assist clients and partners as part of intervention and development initiatives. You recommend solutions to improve or optimize standards, policies and programs. Your projects and initiatives require extensive knowledge of your line of work., , You prepare recommendations, solutions and action plans based on the organization’s objectives and priorities. You help solve complex problems using your analytical skills and extensive knowledge of your line of business. Coordination is critical, so you frequently interact with stakeholders working in other fields. Interpersonal savvy is therefore essential., , #Teaser, , Do you live and breathe data? Are you passionate for big data, little data, muddled data and all data in between? Do you want to design, implement and populate data models that make it possible to automate our data analytics value chain? Come be at the heart of a data driven organisation by joining a critical service for the proper functioning and operation of a top Canadian insurer. Come innovate and change the world of insurance with us! A world in constant change and in continuous need of data innovation. Be part of the journey!, , We don’t offer you a job, we offer you job satisfaction! #Desjardinsdifference, , #Team, , The Modeling and Best Practices team is looking for a candidate to join us in the unique role as a Data Specialist Advisor. Are you interested in working on a multi-disciplinary team with people from various backgrounds (statisticians, actuaries, data scientists) in a motivating environment in which we focus on developing our people? Does the idea of leveraging your strengths while being challenged to explore data analytics and predictive analytics align with your vision and growth? Then you may be the one we are looking for!, , #What you will do, , As a Data Specialist Advisor for the Modeling and Best Practices team, you will be responsible for:, Developing and maintaining data models for use in advanced analytics., Advising on potential solutions for various data management-related issues., Analyze data and data structures, as well as the design and build of all forms of database schemas (relational, OLAP, Big Data etc.) to support a wide range of strategies for secure data acquisition, data cleansing and blending, data storage, analysis and modeling., Responsible for communication of data management needs and process steps in non-technical language., Responsible for communication of data engineering steps required to industrialize an advanced analytics model in technical language., Developing or improving existing processes., Keeping pace with new advancement in data management and advanced analytics, intent on applying them to your work., Coaching or more junior staff to help disseminate expertise., , #What you bring to the table, A bachelor degree in Statistics, Mathematics, Computer Science or Actuarial Sciences., Minimum of 3 years working across BIG or complex data sets in a statistical / analytical role: academic work experience may be considered., Experience with open source cloud-based platforms, Microsoft Azure, or any other public / private cloud based platforms, Expertise in working with structured data; apply methods, technologies and techniques that address data architecture, integration and governance of data, Experience in database concepts, data modelling; data integration including design and architecture, Knowledge of master data management principles and experience with data catalog applications, Expertise in working with unstructured data; ability to apply semantic correlation, ontology and text analytics techniques and systems to analyze non-structured data and identify critical insights for overall business analytics across various domains, Possess solid skills in SAS, SQL, R, and Python (Hadoop, Java, Scala and C++ knowledge / experience is an asset)., Provide thought-leadership and dependable execution on diverse projects, Relevant P&C insurance experience is an asset., English proficiency, both oral and written (for postings in Quebec). Bilingualism is an asset., Required qualities: client-focused, adaptable, team-oriented, curious, can-do attitude, good synthesizing, communication and stakeholder management skills., , #What we offer, Training and development opportunities to grow your career with one of Canada’s top 100 employers., Flexible work options and paid time off to support your personal and family needs., A holistic approach to your well-being, with physical and mental health programs and a supportive workplace culture., A comprehensive compensation package, including competitive salary, bonus, defined benefit pension plan and benefits., Fitness reimbursement program., Discounts on automobile and home insurance premiums., Full reimbursement of Insurance Institute of Canada courses., Free second-language course in the workplace., Reimbursement of job-related continuing education costs., Time off for study days for actuarial examinations., , Desjardins Cross-sector Skills, , Action oriented, Collaborates, Customer Focus, Innovation, , Key competencies for the job, Action oriented, Business insight, Collaborates, Customer Focus, Innovation, Interpersonal Savvy, , Work Location, 95 St-Clair Avenue West Toronto, , Trade Union, Non Syndiqué, , Unposting Date, 2020-06-25, , Job Family, Actuarial Services (FG)","Desjardins Group is the leading cooperative financial group in Canada and the fifth largest cooperative financial group in the world with assets of $227 billion. It has been rated one of Canada’s top 100 employers by Mediacorp Canada. To meet the diverse needs of its members and clients, Desjardins offers a full range of products and services to individuals and businesses through its extensive distribution network, online platforms and subsidiaries across Canada. The group has one of the highest capital ratios and credit ratings in the industry. It is considered as the fourth safest and strongest bank in North America according to Global Finance magazine 
and the first according to Bloomberg News."
2020/06/08 05:41:39,https://www.linkedin.com/jobs/view/1677947205/?eBP=CwEAAAFyk0l8hZvGFMqbwKJKnLGFwmUSDMQcki0SUWEinLkep7lXwDs3rLApXmZi3KgllmgtNP0HFpRFEFo20MFBhtTUwXPw5pB-RjpCkOcPRuZ4UIpk034_NsyZ6gOf72KEh-hlg3PPszu7RJzR-6gtASh2930YoeMpHjs9j1rXpk09LQRjzzGNqnnCg-kTGwcamHRU1Us5Q_j7AU5PQ6Ip1UyF58KDi3PjbHk-Hi-5xfOsRTjnYmZ6HzYkZG940qDF-afRHEx8khBSKcDYUrqE4MFNBfY5pKTZqp18YCAwNYvS2_knR6feGAWduSsVU982El5668-ZCfdSNymky2Z0JC13zDGp87oLZQKhCrzHKyl5Tp3kFgdwdGk2sOaONTdafYiOJXuKWVDt3g&recommendedFlavor=SCHOOL_RECRUIT&refId=e98f7dc7-ff97-42d3-afb7-354d4b7be601&trk=flagship3_search_srp_jobs,Data Visualisation Engineer - Cryptowatch (Remote),Kraken Digital Asset Exchange,"Toronto, Ontario, Canada",Posted 5 days ago,71,"['SQL', 'Python (Programming Language)', 'Cascading Style Sheets (CSS)', 'Java', 'HTML', 'Data Analysis', 'JavaScript', 'Microsoft Office', 'Microsoft Excel', 'MySQL']","['29 Entry level applicants', '15 Senior level applicants', '1 VP level applicant', '1 Manager level applicant']","['71% Applicants', '1% Applicant in the past day']",Associate,Full-time,"['Financial Services', 'Computer & Network Security', 'Information Technology & Services']","This role is fully remote., , Help us scale Cryptowatch, Kraken's professional charting and trading platform. Cryptowatch has grown organically from a tiny weekend project to a popular, real-time cryptocurrency charting and trading platform which people rely on all over the world. We are seeking talented individuals to help us expand the product in new directions. There's rarely a boring day in crypto, and we're looking for people who want to be part of this exciting ecosystem!, , Responsibilities, Develop efficient and complex user interfaces with React and Redux, Migrate existing code from old communication patterns to Redux, Maintain a well organized codebase of components, Write code that works across current versions of all major browsers, Think through edge cases and unexpected user interactions to develop a robust UX, Structure pages to optimize for fast load time and efficient API calls, Optimize existing code to minimize waste of client resources, Collaborate with backend engineers to implement backend requirements for new interfaces, , Requirements, Expertise using React and Redux, Experience writing code in ES6 syntax, Experience working with Webpack, Experience writing CSS using SASS abstractions, Experience using developer tools to debug and profile JavaScript code, Experience working with both REST and websocket APIs, Ability to independently navigate a large codebase to find logic and debug problems, Ability to collaborate with remote employees (developers and designers), , A strong candidate will also:, Have an eye for visual balance and harmony, Be proficient with HTML5 canvas, Have experience working with websocket clients and protocol buffers","Kraken is one of the largest and most successful bitcoin exchanges in the world and we’re growing faster than ever. We’re looking for people who constantly push themselves to think differently and chart exciting new paths in a rapidly growing industry. Kraken is a diverse group of dreamers and doers, we truly believe our success depends on having both in spades. Join us and the movement to change the way the world thinks about money. 

 Check out all our open roles at https://jobs.lever.co/kraken. We’re excited to see what you’re made of.   
We’re powered by people from the around the world with their own unique backgrounds and experiences. We value all Krakenites and their talents, contributions, and perspectives."
2020/06/08 05:42:15,https://www.linkedin.com/jobs/view/1890770853/?eBP=JOB_SEARCH_ORGANIC&recommendedFlavor=COMPANY_RECRUIT&refId=e98f7dc7-ff97-42d3-afb7-354d4b7be601&trk=flagship3_search_srp_jobs,"Senior Research Engineer, Big Data",Rakuten Kobo Inc.,"Toronto, CA",Posted 5 days ago,33,"['Machine Learning', 'Python (Programming Language)', 'SQL', 'C++', 'Data Analysis', 'Algorithms', 'MATLAB', 'Deep Learning', 'Computer Vision', 'Apache Spark']","['15 Senior level applicants', '10 Entry level applicants', '1 Director level applicant']","['33% Applicants', '1% Applicant in the past day']",Mid-Senior level,Full-time,['Consumer Electronics'],"Job Description, , Here at Rakuten Kobo Inc. we offer a casual working start-up environment and a group of friendly and talented individuals. Our employees rank us highly in terms of commitment to work / life balance. We realize that for our people to be innovative, creative and passionate they need to have healthy minds and bodies. We believe in rewarding all our employees with competitive salaries, performance based annual bonuses, stock options and training opportunities., , If you’re looking for a company that inspires passion, personal, and professional growth – join Kobo and come help us make reading lives better., , The Role, , Each month, Kobo.com hosts millions of shopping sessions for readers all around the world, and our ecosystem of e-reading devices, apps, websites, partners and APIs captures over a BILLION tracked events in the same timeframe. The Big Data team is responsible for harnessing this huge amount of data to personalize & improve the user experience, drive sales, and help make the world a better place with the power of reading!., , We are seeking a Senior Researcher, Big Data to join our team. The ideal candidate has an academic background in ML/AI, and hands on experience applying this knowledge in an e-commerce context to drive personalized experiences for customers. You will be working with Big Data developers, Data Engineers, Data Scientists, and our Data Architect to propose novel approaches to our problem space, and will be supported in executing these in A/B test format against our millions of readers. You possess a knack for being able to communicate the concepts & technology to both layman and expert audiences, and can blueprint the steps from hypothesis through to deployment into the production world., , You will be part of a diverse, flexible, and collaborative environment where you will be able to apply and develop your skills and knowledge working with unique data and exciting applications., , Responsibilities, Build, optimize, and deploy production-quality code for our search, recommendations and content analysis research projects., Research novel ML solutions and apply them to existing systems and codebase, Build powerful models while balancing the need for explainability and transparency, , Requirements, , The Skillset:, Undergraduate degree or equivalent in Computer Science, Computer or Electrical Engineering, or related field., First hand experience designing and improving Machine Learning / AI software projects, using frameworks such as Tensorflow or PyTorch., Expertise in designing, implementing, testing and deploying Big Data software solutions., Experience with image processing algorithm development, natural language processing and text-analysis., Experience working with distributed Big Data tools such as Spark, Hadoop, Storm, Hive and Flume or equivalents., Candidates will be required to complete a coding test as part of the interview process., , The Perks, Flexible hours, Optional work from home for the remainder of 2020, Full benefits starting from your first day, Paid Volunteer days, unlimited sick days, and 3% RRSP matching, Monthly commuting allowance and internet allowance, Flexible health spending account, Talent and development training budget, Free Kobo device + free weekly e-book or audiobook, Weekly Kobo Tech University sessions, Maternity/paternity leave top up, , About Rakuten Kobo Inc., , Owned by Tokyo-based Rakuten and headquartered in Toronto, Rakuten Kobo Inc. is one of the world’s most innovative eReading services offering more than 6 million eBooks and audiobooks to millions of customers in 190 countries. Believing that consumers should have the freedom to read any book on any device, Kobo provides people with a choice when reading. Kobo offers an eReader for everyone with a wide variety of E Ink eReaders to suit any Reader’s style including Kobo Clara HD, Kobo Aura H2O, and Kobo Aura ONE; along with the company’s free top-ranking eReading and audiobook listening app for Apple® and Android®. Kobo’s award-wining eReaders can be found in major retail chains around the world. For more information, visit www.kobo.com., , Rakuten Kobo Inc. is an equal opportunity employer. Accessibility accommodations for candidates with disabilities participating in the selection process are available on request. Any information received related to accommodation needs of applicants will be addressed confidentially., , Rakuten Kobo would like to thank all applicants for their interest in this role however only qualified candidates will be shortlisted.","Rakuten Kobo Inc. is the world’s only dedicated digital bookseller. 

Owned by Tokyo-based Rakuten and headquartered in Toronto, Kobo enables more than 30 million readers worldwide to read anytime, anywhere and on any device.

 With our award-winning eReaders and the free Kobo App for smartphones and tablets, Kobo is your portable reading world."
2020/06/08 05:42:52,https://www.linkedin.com/jobs/view/1852859252/?eBP=NotAvailableFromVoyagerAPI&recommendedFlavor=SKILL_ASSESSMENTS&refId=e98f7dc7-ff97-42d3-afb7-354d4b7be601&trk=flagship3_search_srp_jobs,Data Engineer,Workbridge Associates,"Toronto, CA",Posted 1 month ago,,,,,Entry level,Full-time,"['Information Technology & Services', 'Computer Software', 'Internet']","A San Francisco based software company that has an engineering team in downtown Toronto is currently expanding, and they are in need of Data Engineers., , You will work in a small and tight-knit engineering unit who take a project-based agile approach to software development and provide technical vision to the architecture and design of cloud native systems built for scale., , The role will focus on dedication, team growth and empowerment through building a culture of responsibility and knowledge transfer. Some of the requirements will be designing and building a streaming pipeline that handles thousands of events per second, architect and scale AWS data pipelines., , Required Skills & Experience, 4+ years of Data Engineering experience, Experience with AWS, Docker, Kubernetes., Experience with Schema Registry., Experience building microservices & Architecture Design Skills., Strong coding skills (Java or Python preferred), Experience with Document stores like Firestore/ Couchbase., , , Desired Skills & Experience, Computer Science or related degree, Technical leadership and team management experience., , The Offer, Competitive Pay: $125,000/yearly depending on exp, Equity, Standard Benefits (Health, Dental, Vacation), , , Applicants must be currently authorized to work in Canada on a full-time basis now and in the future., , This position does not offer sponsorship., , Workbridge Associates, part of the Motion Recruitment network, provides IT Staffing Solutions (Contract, Contract-to-Hire, and Direct Hire) across 11 major North American markets. Our unique expertise in today’s highest demand tech skill sets, paired with our deep networks and knowledge of our local technology markets, results in an exemplary track record with candidates and clients","Workbridge, part of the Motion Recruitment network, provides IT Staffing Solutions (Contract, Contract-to-Hire, and Direct Hire) across 12 major North American markets, helping companies to find, attract, hire and grow with the best tech talent on the market. Specializing within six tech disciplines, our teams master the local tech marketplace, resulting in a truly consultative approach and proven track record within our recruiting areas of expertise: Software, Mobile, Infrastructure, Data, Creative and Functional.
 
Workbridge is also a proud creator of Tech in Motion and the Timmy Awards; our North American events and awards connect nearly 200,000 tech enthusiasts to meet, learn, and innovate in their communities and beyond."
2020/06/08 05:43:31,https://www.linkedin.com/jobs/view/1830180592/?eBP=NotAvailableFromVoyagerAPI&recommendedFlavor=SKILL_ASSESSMENTS&refId=e98f7dc7-ff97-42d3-afb7-354d4b7be601&trk=flagship3_search_srp_jobs,Data Science Team Lead,Loblaw Digital,"Toronto, CA",Posted 1 month ago,48,"['Python (Programming Language)', 'Machine Learning', 'SQL', 'R', 'Statistics', 'Data Analysis', 'Data Science', 'Research', 'MATLAB', 'Leadership']","['22 Senior level applicants', '11 Entry level applicants', '6 Manager level applicants', '3 Director level applicants']","['48% Applicants', '1% Applicant in the past day']",Associate,Full-time,"['Information Technology & Services', 'Computer Software', 'Internet']","At Loblaw Digital, we know that our customers expect the best from us.Whether that means building the best, most innovative online shopping experience, or designing an app that will impact the lives of people across the country, we’re up for the challenge. From our office in Downtown Toronto, we’ve created leading eCommerce experiences in the online grocery shopping, beauty, pharmacy, and apparel spaces, and we’re only just getting started., , The impact you’ll make, , As a Data Science Team Lead, you will lead a world-class team of data and machine-learning experts as we build predictive models that solve real problems for the business, both for our customers and internal stakeholders. The data science team at Loblaw Digital drives customer experience both through personalization in our web and mobile applications, and through forecasting used to optimize labor and availability, which have significant impact upon a customer’s interaction with the physical business at delivery and pickup. You’ll play a leading role in deciding what technologies we use and what things we build, working closely with product and software development teams to imagine best-of-breed solutions that drive our business forward. You’ll work alongside a talented team with diverse backgrounds and a broad spectrum of skills, and have the benefit of an industry-leading tech stack that uses cloud-native technologies on GCP, and includes Kubernetes, Kafka, Spark, and BigQuery., , What You'll Do, Provide technical leadership to a dynamic and growing data science team, Provide people leadership to several data scientists, Work with the BI and Data Platform teams to plan the ingestion of data sources required for development of new models and services, Lead the development of ML models that help us drive a customer-centric retail business, with relevant recommendations in-shop and tighter fulfillment operations, Use forecasting models to solve problems ranging from demand to user behavior, Does this sound like you?, MS or PhD in math, engineering, computer science, or related technical field, or equivalent practical experience, Extensive experience with python and scikit-learn or other MLpackages, Deep SQL chops, Strong ability for prioritization and communication, Prior people and/or project management experience, Experience shipping ML models to production, Experience with cloud platforms such as AWS/GCP/Azure, Experience with BigData tools such as Spark, Hadoop, Kafka, Experience with dataviz tools such as Tableau, Looker, etc a bonus, , How You’ll Succeed, , At Loblaw Digital, we seek great people to continually strengthen our culture. We believe great people model our values, are authentic, build trust and make connections. We’re able to keep innovating because our colleagues are passionate about their work and excited about the future of eCommerce., , You will get to work with some of the best digital minds and will have the support of world class technologies to craft products our customers will love!, , Loblaw Digital recognizes Canada's diversity as a source of national pride and strength. We have made it a priority to reflect our nation’s evolving diversity in the products we sell, the people we hire, and the culture we create in our organization. Accommodation is available upon request for applicants with disabilities in the recruitment and assessment process and when hired., , In addition, we believe that compliance with laws is about doing the right thing. Upholding the law is part of our Code of Conduct – it reinforces what our customers and stakeholders expect of us.","Looking for a challenge? Good. Love an innovative work environment? Even better.

At Loblaw Digital, we know that our customers expect the best from us. Whether that means building the best, most innovative online shopping experience, or designing an app that will impact the lives of people across the country, we’re up for the challenge. From our office in Downtown Toronto, we’ve created leading eCommerce experiences in the online grocery shopping, beauty, pharmacy, and apparel spaces, and we’re only just getting started.

We’re able to keep innovating because our colleagues are passionate about their work and excited about the future of eCommerce. If you have big ideas, undeniable enthusiasm, and thrive in a collaborative, creative, and diverse group, we’ll get along just fine."
2020/06/08 05:44:07,https://www.linkedin.com/jobs/view/1837440250/?eBP=CwEAAAFyk0l8haHE991HcVCIuQWrY9Dpalcolt98pLe_2Mrsv7jO-LwQKVxHlS7bzM6K0Al7k039KdSES6PrxToskk48mest-MrxZ5oRTXwQmMpm0DUPcSTzBfaUrCIaCo_wWQCP8tzeCTzSqsEYj7kPQiHnX8kDSC7iPXbXofD-bm8fcLfXHlTV4kNHue3nrIyAkHZ4p1UmUDzwVi8Caz4VTZdK021RoD08fao3xVqrX5C9xFajM7NIEHfs5cQ3r6eRxy3ZvHgPvienUTbWonXVc6nCKBBPuSLu7zKlEc_aNxuzp1VX58lblbrGpZGt6ExYEQFKlpE9DixUt0wOQ12Jm5Qir2bg8Ey8_KXkuENijM2w3pkEfDxUQUuzvp04PL4-dDiGGYLeWnWLYuER&recommendedFlavor=SKILL_ASSESSMENTS&refId=e98f7dc7-ff97-42d3-afb7-354d4b7be601&trk=flagship3_search_srp_jobs,Applications Engineer,Ontario Teachers' Pension Plan,"Toronto, CA",Posted 2 weeks ago,,"['Java', 'SQL', 'Python (Programming Language)', 'C++', 'Microsoft Office', 'Microsoft Excel', 'C (Programming Language)', 'Leadership', 'JavaScript', 'MySQL']","['23 Entry level applicants', '13 Senior level applicants', '3 Manager level applicants']",,Entry level,Full-time,"['Financial Services', 'Investment Management']","Applications Engineer, , The opportunity, , We are adding an Applications Engineer to our Enterprise Operations team as part of our organization-wide investment in new and optimized technology. As our next Applications Engineer, you will play a critical role in migrating our legacy on-premise solutions to a hybrid Azure cloud environment. This is a chance to apply your expertise in infrastructure and architecture as you grow your knowledge in virtualization and cloud services., , Who You'll Work With, , Reporting to the Senior Manager, SaaS & PaaS Services, you will deliver a variety of enterprise systems and manage several key systems critical to our business functions. In this role, you will be part of a collaborative and innovative team, dedicated to introducing a strengthened technology foundation across the organization. This is a nimble team, continuously learning through experimentation, research, and professional development opportunities., , What You'll Do, , Build new systems. You will:, Own and manage the end-to-end build of systems, engaging internal teams, vendors, as well as managed service partners, Keep an up to date record of systems and builds, including certificates and licenses, Implement, test, and remediate where required, including HA, backup, alerting, DR, and controls, Support the development of standard build instructions for new technologies, Develop build “As Built” and operational documentation, Transition build knowledge to internal teams to ensure systems meet operational standards, Ensure success in building and migrating applications, software, and services, , Configure And Enhance Existing Systems. You Will, Maintain and support the configuration of SaaS & PaaS infrastructure systems, Drive continuous improvement by supporting and implementing systems upgrades, Collaborate with internal teams; contributing valuable insights to capacity plans and forecasts, Maintain, develop, and enhance application configuration automation frameworks, Track and manage OTPP systems, technologies, and applications across the complete lifecycle, Build APIs that simplify service consumption for our end-users and engineers, Optimize and support existing SaaS & PaaS technology as well as data centre based solutions, Minimize system integration complexity while maintaining system reliability and business continuity, , Constantly expand your knowledge; leveraging it to drive improvements. You will:, Keep up to date with the latest operation system administration procedures and best practices; ensuring learning is documented and shared with the Infrastructure team, Continuously update and build upon your knowledge of accepted industry and company standards to improve service delivery, Collect data and deliver reports on internal technology and processes; suggesting improvements whenever possible, Strategize on how to best meet key business objectives; planning your course of action and executing on it, , What You'll Need, The education. You have a bachelor’s degree in Computer Science, Business Studies, IT or have the equivalent work experience. Ideally, you have your ITIL Foundations and TOGAF certifications., The experience. You have 5+ years of hands-on experience working with application technologies in a cloud environment; preferably Microsoft Azure. You have proven success migrating client applications to the cloud; ideally in the capital markets, finance, or banking industry. You have experience automating application configuration and have successfully instituted SaaS applications from start to finish in the past., The technical knowledge. You have 5+ years of experience with application technologies such as Charles River, SimCorp, Quantum, OneTick, Adaptiv, Office 365, Airwatch, Intune, Datanomics, Lawson, Adobe AEM, Camunda Workflow, UC4, Jive, Liferay, and SAS. You're a skilled scripter with experience in YAML, Powershell, and Python. You are well-versed in SaaS application design including infrastructure, database, and middleware., The people skills. You are comfortable working with individuals at any level and are able to effectively convey your point and gain support from diverse stakeholders. You’re an excellent listener who’s able to understand client needs, manage conflicting demands, and develop a solution that everyone is happy with. An outstanding written and verbal communicator, you have no problem translating client needs into technical requirements and communicate these requirements to internal team members with ease., , What We're Offering, , Salary Range, Pay for performance environment that offers competitive salary and incentive, Numerous opportunities for professional growth and development, Comprehensive employer paid benefits coverage, Guaranteed retirement income through a defined benefit pension plan, Competitive time off, Discount programs including Edvantage and Perkopolis, Degreed: a digital platform that helps you quickly and easily discover, share, and track ALL kinds of learning resources — from courses to videos to articles and more, , At Ontario Teachers', we are a globally minded organization and take pride ensuring that the people we hire and the culture we create reflects and celebrates diversity of thought, background and experience., , If you require an accommodation for the application, recruitment or interview process, please let us know and we will work with you to meet your needs., , How To Apply, , Are you ready to pursue new challenges and take your career to the next level? Apply today!, , We thank you for applying, however, only those selected to continue will be contacted. Note that candidates must be legally entitled to work in the country where this role is located., , Functional Area, , Information Technology, , Requisition ID, , 2309, , The privacy of your personal information is important to us. Please visit our Privacy Centre to learn how we handle your personal information.","Our employees make a difference by providing a secure retirement for 329,000 working and retired Ontario teachers. We have established a collaborative environment and seek the free exchange of ideas across the organization in our search for new approaches and solutions to better serve our members. 

Our highly-skilled employees are the reason for our success and talent development is one of the most important tenets of our strategy. At Ontario Teachers’, we look for people who are willing to truly embrace the three cornerstones of our culture: innovation, agility and partnership. We provide our employees with the tools, resources and learning opportunities they need to be the best at what they do – so together we can support our mandate to deliver outstanding service and retirement security to the working and retired teachers of Ontario – today and tomorrow. 

Ontario Teachers’, Canada’s largest single-professional pension plan, is headquartered in Toronto with offices in London and Hong Kong. With $207.4 billion in net assets as of December 31, 2019, we are responsible for providing immediate, personalized services to our members along with investing across a variety of asset classes in virtually every corner of the world.

Read our Linkedin Terms of Use before engaging with us at: http://www.otpp.com/linkedin-terms-of-use"
2020/06/08 05:44:44,https://www.linkedin.com/jobs/view/1879187922/?eBP=NotAvailableFromVoyagerAPI&refId=e98f7dc7-ff97-42d3-afb7-354d4b7be601&trk=flagship3_search_srp_jobs,Data Engineer,Maarut Inc,"Toronto, CA",Posted 1 week ago,39,"['SQL', 'Python (Programming Language)', 'Data Analysis', 'Machine Learning', 'R', 'Databases', 'Data Warehousing', 'Shell Scripting', 'SQL Server Integration Services (SSIS)', 'Extract, Transform, Load (ETL)']","['2 Entry level applicants', '1 Senior level applicant']","['39% Applicants', '2% Applicants in the past day']",Mid-Senior level,Contract,['Nanotechnology'],"We are looking for Data Engineer with 6+ yrs of experience in Data Analysis to join our client in banking sector with the below skills, , Skills, 6+ Yrs of Experience in Information Technology with 5+ Yrs of Data Analytics / Business Intelligence experience, 2+ Yrs of experience in ETL Tools and Data extraction, Hands on experience as Data Engineer, Experience with Data Lineage, ETL, Oracle , PL/SQL, Big data with business analysis background, Previous Banking experience, Experience in Basel Projets (preferred)","Maarut Inc is a Canadian company helping organizations fulfill staffing solutions based on current, future and ongoing needs of market.

Register with us : https://zfrmz.com/e7c6tlOfwj7SCGbkd2N0

Finding IT talent is a significant challenge in today’s business landscape. Maarut Inc has the unique methodology for identifying, acquiring and retaining top IT resources across various areas of expertise. We help companies hire better candidate, and make meaningful relationships between the job seeker and the employers. 

Engaging the right people with the right skills and experience can make or break your company. As an employment agency representing many talented skilled professionals who can pinch in immediate on projects, fill team gaps and support growth, we quickly deliver the exact talent you require for your needs.

Our goal is to craft flexible, targeted solutions as per your staffing needs by matching the right people, to the right job, at the right time.
Our recruiters are savvy insiders, having worked in the industries for which they recruit. They’ve walked in your shoes, so they understand the exciting, satisfying and challenging aspects of each job. They understand what makes IT placement unique, team dynamics and how each company and candidate are special. 

Our recruitment team is specialized in identifying the top technical consultants with skill sets such as:

Application Development
Big Data
Business Intelligence/Reporting
Business Systems Analysis
Data Warehousing
Database
Devops Engineers
ERP/SCM/CRM
Guidewire consultants
Incident management Professionals
Infrastructure
Mainframe
Project Management
Quality Assurance
Salesforce consultants
Web Development/Design

Apply for jobs now or Register yourself now 
https://www.maarutinc.com/applyjobs"
2020/06/08 05:59:40,https://www.linkedin.com/jobs/view/1881210124/?eBP=CwEAAAFyk0l8hYxi7JzFAsCLacHVuvOK5H2VDEatWo4a4sOcFVYk4GukL1Yxs3ghBAH93l9bIroySaAQveR_I10P6nIpmFaZwd1pjlHpyk2cRQhec7HXxlnDXugedXlIwgG30cwYBFoS5HKu9Bfyl4aQ7dM62jhlHhUM8Eid8rdev94BBikUmThTRdIMbCkh7-h8eUOyJaJ-ViVGoNxRUQQDJG23SuQwcAAsAnRm0WYYk3GY0v7J9OCvx33OFgygAb4UEz1zfrAOP-M4hh8dAzQyH1MAKx-xS0MoMparzxpYSdK4jawD3CHDdZh9oAWNzEkiX7fxz2i4KiaLv7_P_MFwpDKE2pHS_nShrz2YDfbu4N7caV_1jlRBWvxAHwm2OKvJQzii1YJY117lNhht&recommendedFlavor=SKILL_ASSESSMENTS&refId=e98f7dc7-ff97-42d3-afb7-354d4b7be601&trk=flagship3_search_srp_jobs,Data Specialist Advisor,Desjardins,"Toronto, CA",Posted 1 week ago,69,"['SQL', 'Data Analysis', 'Python (Programming Language)', 'R', 'Microsoft Excel', 'Microsoft Office', 'Tableau', 'Business Intelligence (BI)', 'Data Visualization', 'Project Management']","['21 Senior level applicants', '16 Entry level applicants', '5 Manager level applicants', '1 Director level applicant']","['69% Applicants', '2% Applicants in the past day']",,Full-time,"['Information Technology & Services', 'Computer Software', 'Insurance']","Desjardins Group is the largest cooperative financial group in Canada, and one of the largest employers in the country. It offers a full range of financial products and services and is home to a wealth of expertise in property and casualty insurance, life and health insurance, wealth management, services for businesses of all sizes, securities brokerage, asset management, venture capital, and secure, leading-edge virtual access methods., , Job Level, AC-09, , As an actuarial and statistical advisor, you help ensure profitability and balanced risk-return ratios for products and services. You also establish reserves, produce statistical models that inform decision-making, and analyze problems and business opportunities for the organization’s actuarial initiatives., , You advise and assist clients and partners as part of intervention and development initiatives. You recommend solutions to improve or optimize standards, policies and programs. Your projects and initiatives require extensive knowledge of your line of work., , You prepare recommendations, solutions and action plans based on the organization’s objectives and priorities. You help solve complex problems using your analytical skills and extensive knowledge of your line of business. Coordination is critical, so you frequently interact with stakeholders working in other fields. Interpersonal savvy is therefore essential., , #Teaser, , Do you live and breathe data? Are you passionate for big data, little data, muddled data and all data in between? Do you want to design, implement and populate data models that make it possible to automate our data analytics value chain? Come be at the heart of a data driven organisation by joining a critical service for the proper functioning and operation of a top Canadian insurer. Come innovate and change the world of insurance with us! A world in constant change and in continuous need of data innovation. Be part of the journey!, , We don’t offer you a job, we offer you job satisfaction! #Desjardinsdifference, , #Team, , The Modeling and Best Practices team is looking for a candidate to join us in the unique role as a Data Specialist Advisor. Are you interested in working on a multi-disciplinary team with people from various backgrounds (statisticians, actuaries, data scientists) in a motivating environment in which we focus on developing our people? Does the idea of leveraging your strengths while being challenged to explore data analytics and predictive analytics align with your vision and growth? Then you may be the one we are looking for!, , #What you will do, , As a Data Specialist Advisor for the Modeling and Best Practices team, you will be responsible for:, Developing and maintaining data models for use in advanced analytics., Advising on potential solutions for various data management-related issues., Analyze data and data structures, as well as the design and build of all forms of database schemas (relational, OLAP, Big Data etc.) to support a wide range of strategies for secure data acquisition, data cleansing and blending, data storage, analysis and modeling., Responsible for communication of data management needs and process steps in non-technical language., Responsible for communication of data engineering steps required to industrialize an advanced analytics model in technical language., Developing or improving existing processes., Keeping pace with new advancement in data management and advanced analytics, intent on applying them to your work., Coaching or more junior staff to help disseminate expertise., , #What you bring to the table, A bachelor degree in Statistics, Mathematics, Computer Science or Actuarial Sciences., Minimum of 3 years working across BIG or complex data sets in a statistical / analytical role: academic work experience may be considered., Experience with open source cloud-based platforms, Microsoft Azure, or any other public / private cloud based platforms, Expertise in working with structured data; apply methods, technologies and techniques that address data architecture, integration and governance of data, Experience in database concepts, data modelling; data integration including design and architecture, Knowledge of master data management principles and experience with data catalog applications, Expertise in working with unstructured data; ability to apply semantic correlation, ontology and text analytics techniques and systems to analyze non-structured data and identify critical insights for overall business analytics across various domains, Possess solid skills in SAS, SQL, R, and Python (Hadoop, Java, Scala and C++ knowledge / experience is an asset)., Provide thought-leadership and dependable execution on diverse projects, Relevant P&C insurance experience is an asset., English proficiency, both oral and written (for postings in Quebec). Bilingualism is an asset., Required qualities: client-focused, adaptable, team-oriented, curious, can-do attitude, good synthesizing, communication and stakeholder management skills., , #What we offer, Training and development opportunities to grow your career with one of Canada’s top 100 employers., Flexible work options and paid time off to support your personal and family needs., A holistic approach to your well-being, with physical and mental health programs and a supportive workplace culture., A comprehensive compensation package, including competitive salary, bonus, defined benefit pension plan and benefits., Fitness reimbursement program., Discounts on automobile and home insurance premiums., Full reimbursement of Insurance Institute of Canada courses., Free second-language course in the workplace., Reimbursement of job-related continuing education costs., Time off for study days for actuarial examinations., , Desjardins Cross-sector Skills, , Action oriented, Collaborates, Customer Focus, Innovation, , Key competencies for the job, Action oriented, Business insight, Collaborates, Customer Focus, Innovation, Interpersonal Savvy, , Work Location, 95 St-Clair Avenue West Toronto, , Trade Union, Non Syndiqué, , Unposting Date, 2020-06-25, , Job Family, Actuarial Services (FG)","Desjardins Group is the leading cooperative financial group in Canada and the fifth largest cooperative financial group in the world with assets of $227 billion. It has been rated one of Canada’s top 100 employers by Mediacorp Canada. To meet the diverse needs of its members and clients, Desjardins offers a full range of products and services to individuals and businesses through its extensive distribution network, online platforms and subsidiaries across Canada. The group has one of the highest capital ratios and credit ratings in the industry. It is considered as the fourth safest and strongest bank in North America according to Global Finance magazine 
and the first according to Bloomberg News."
2020/06/08 06:01:20,https://www.linkedin.com/jobs/view/1689812416/?eBP=CwEAAAFyk1wBr89a4dFqZXmp2uYAW30HzfwhvUEBREV36o_f9N-wid-0aGoQaJ4iQFsWwOOCqkO7As6IcuRL_mIpmAAH9dnPYOemejMA81_gfA7g0SFXBy01UVUnGp6DbnFABAxHUej47vsocoPeSrt1IOnloCwCyIRdYAOydEtB2SAsZu5dJMnMYy29kxiuGeo-cuvkSKVg3GJAkPJ3FlxcwWvbtpfEukKZ3Gbgwg-xlbq8DEt8ITIGabn16xT8Vka4TWvaSwjFpXqC2guMbutr8X1fsKqVRkx68Jv5VHegoz-JJ-hh1oci5ODwZX_sXpDOSOnfEBdBaldZHPP4Y0Pr1uDPyjvhyVmbkHPAuI89XkchMcPHKoWycTATxxGbjo9AauCPm79vyJQFZ_Un&recommendedFlavor=COMPANY_RECRUIT&refId=d318dc0e-7b4c-4f7e-877e-312a5749f86e&trk=flagship3_search_srp_jobs,Senior Data Engineer,Nomis Solutions,"Toronto, Ontario, Canada",Posted 6 days ago,,"['SQL', 'Python (Programming Language)', 'Java', 'Data Analysis', 'Hadoop', 'Machine Learning', 'Apache Spark', 'MySQL', 'Tableau', 'Amazon Web Services (AWS)']","['66 Entry level applicants', '34 Senior level applicants', '1 VP level applicant', '1 Director level applicant']",,Associate,Full-time,['Computer Software'],"Senior Data Engineer, Nomis is looking for an outstanding data expert to join our team. The Data Engineer will collaborate closely with our client services team to process critical data while working to power advanced analytics and enable the integration of data science across the company. You are ready to be flexible and nimble in your work, from constructing ETL pipelines for customer delivery to participating in exploratory data analysis with our Analytics team. , Who We Are & What We Build, , We partner with Banks and FinTechs on their journey to best-in-class pricing technology and analytics so that they deliver more value to their customers, employees and shareholders. Our top-notch people, proven technology, and innovative analytics are tackling big data challenges at banks and lenders every day. We deliver market-leading cloud-based Pricing & Profitability Management solutions and insights for the Banking & Financial Services industry leveraging cutting-edge behavioral data science. We are a Blue Chip venture-backed company with the vision to transform the consumer banking landscape. , Responsibilities, Establish and maintain big data processing platform, Build data management applications and microservices on AWS, Design and implement Hive/Greenplum/RedShift distributed data warehouses and standard schemas, Design, develop, maintain cross-platform ETL processes and MapReduce/Hive/Spark data processing workflows, Manage and maintain reference data securely on S3 and other storage systems, Support client services teams by, Manage, customize, and automate cloud-based (AWS) data processing supporting multiple clients, Administration of relational databases, capacity plans, infrastructure and storage design, Oversee and execute data migration from existing data stores, Application/implementation of custom analytics applications and datasets, Develop code standards, guidelines, and automated test suites to ensure highest data quality and integrity, Desired Skills and Requirement, Experience with building distributed systems, query processing, and the Hadoop ecosystem , Understanding of Data warehousing - architect and design data warehouse, Expertise with data schema - logical and physical data modeling, Knowledge of ETL processes and tools, Experience with AWS or a major cloud platform such as GCP, Proficiency in: Python, SQL, Java, Strong pluses:, Experience of Business Intelligence tooling such as Tableau, Experience with data mining techniques and analytics functions, Predictive analytics experience is a PLUS, Experience with Spark 2, Apache Airflow and other modern data engineering tooling a strong plus, Experience with streaming architectures and MPP databases such as Greenplum a strong plus, Up-to-date with the open-source community w.r.t. data engineering, Experience with the following services in AWS a strong plus: EMR, Lambda, Kinesis, Firehose, S3","Nomis helps retail banks deliver win-win customer engagement through price optimization, customer-centric offers, and omni-channel sales enablement. More than 10,000 bankers worldwide leverage Nomis’ cutting-edge Silicon Valley approach to big data, advanced modeling, and deep analytics to understand and anticipate the demands of their customers, competitor actions, and dynamic market conditions. With experience in over 80 implementations, Nomis has a proven track record of increasing customer and stockholder value, returning more than $300 million to its partner banks every year. Banks currently use Nomis technology to manage more than 270 million accounts and optimize over $1 trillion in banking transactions annually.


We are headquartered in Silicon Valley with offices in Melbourne, Australia, and Toronto. Our customers include 20 of the top 100 banks globally and 10 of the top 40 retail banks in North America."
2020/06/08 06:01:59,https://www.linkedin.com/jobs/view/1871507456/?eBP=CwEAAAFyk1wBrlL4mYKKWa_Yg3e4XSsL2GHqOFKMUhxcZ6vkSGJ1Lz3ybpCXTcy3ymw84mR2EMRak2XiiKwwUjuDNlNcvstxLdG7GVmWTjZS3k-irQl40hafCcK77w6kFS7OAEBFmg8H2AaFW_vmWlE2YtHiJV4uEimoJdS0Gq-iWSIyCQY85ucdNS1vWf-Cs_2JN2_CdieEwA2MPZrReeZ7ld8o7wc2pyUvrKizHXEEq3C-aeTz4kYEZajPy3E-8ahBII7CWEacg791w-iKs2Qy4zWabiQnPkFHAfA1JMCqoCKubgh2U77Nb4CLPHTz91rQPXHnxetzFDILXgBBKwQIqCmAslLZtkS73vZ_8Uuph1W-mk98dpyJ0Fs3jTPcAUMptkGwzRV2JRGgLYFr&recommendedFlavor=SKILL_ASSESSMENTS&refId=d318dc0e-7b4c-4f7e-877e-312a5749f86e&trk=flagship3_search_srp_jobs,Senior Data Engineer,FreshBooks,"Toronto, Ontario, Canada",Posted 2 weeks ago,47,"['SQL', 'Python (Programming Language)', 'Java', 'Hadoop', 'Data Analysis', 'Big Data', 'MySQL', 'Apache Spark', 'Databases', 'Data Warehousing']","['24 Senior level applicants', '14 Entry level applicants', '3 Manager level applicants', '1 VP level applicant']","['47% Applicants', '1% Applicant in the past day']",Mid-Senior level,Full-time,"['Computer Software', 'Internet', 'Computer & Network Security']","FreshBooks has a big vision. We launched in 2003 but we’re just getting started and there’s a lot left to do. We're a high performing team working towards a common goal: building an elite online accounting application to help small businesses better handle their finances. Known for extraordinary customer service and based in Toronto, Canada, FreshBooks serves paying customers in over 120 countries., , The Opportunity - Senior Data Engineer, FreshBooks is seeking a Senior Data Engineer to join our team. You will help build new features and update existing ones in our current data pipeline infrastructure. If you’re committed to great work and are constantly looking for ways to improve the systems you’re responsible for, we’d love to chat with you!, , What you'll do:, Collaborate with data engineers and full-stack developers on cross-functional agile teams working on features for our stakeholders., Technically lead and mentor a group of data engineers., Work closely with our analytics, data science, product and other internal business teams to ensure their data needs are met., Participate and share your ideas in technical design and lead architecture discussions., Ship your code with our continuous integration process., Provide coaching on data engineering best practices and share and learn from your peers., Develop your craft and build your expertise in data engineering., , What you bring:, Enthusiasm for data engineering!, Experience creating and maintaining data pipelines for the past 5 years., Experience with AWS, or another major cloud provider such as Google Cloud Platform., Experience with Redshift, Big Query, or similar cloud storage technologies., Strong programming skills in Python or similar language., Good experience in mentoring peers and intermediate data engineers., A strong practitioner of test-driven (and behavioural test-driven) development., Experience with Git workflows, continuous integration and automated build pipelines., Experience working in an Agile environment.,  What you might bring:, A track record of staying at the forefront of data engineering technology., Experience with BI tools: Periscope, Looker., Experience with Spark, Kafka, Flink, Dataflow, or other streaming technologies., Experience with Docker, Kubernetes, Terraform, and other DevOps and infrastructure as code technologies., A limitless imagination for where data could go and what we can do with it to make our customers and our people awesome!, , Why Join Us, We're an ambitious bunch, with our eyes laser-focused on shipping extraordinary experiences to small business owners. You'll be surrounded by talented team members who share a common vision for what an amazing software company could be, and have the opportunity to help build a world-class one, right here in Toronto, Canada., , Apply now, Have we got your attention? Submit your application today and a member of our recruitment team will be in touch with you shortly!, , FreshBooks is an equal opportunity employer that embraces the differences in all of our employees. We celebrate diversity and are committed to creating an inclusive environment for all FreshBookers. All applicants are evaluated based on their experience and qualifications in relation to this position., , FreshBooks provides employment accommodation during the recruitment process. Should you require any accommodation, please indicate this on your application and we will work with you to meet your accessibility needs. For any questions, suggestions or required documents regarding accessibility in a different format, please contact us at phone 416-780-2700 and/or accessibility@freshbooks.com","#1 accounting software in the cloud for self-employed professionals and their teams.

Other ways to connect with us: 
Visit the FreshBooks Blog: freshbooks.com/blog
Send us a tweet: twitter.com/FreshBooks
Find career opportunities: freshbooks.com/careers"
2020/06/08 06:02:38,https://www.linkedin.com/jobs/view/1890686149/?eBP=NotAvailableFromVoyagerAPI&recommendedFlavor=SKILL_ASSESSMENTS&refId=d318dc0e-7b4c-4f7e-877e-312a5749f86e&trk=flagship3_search_srp_jobs,Database Engineer (Python/SQL/VBA),BeachHead,"Toronto, CA",Posted 6 days ago,,,,,Entry level,Contract,"['Information Technology & Services', 'Computer Software', 'Financial Services']","Are you passionate about developing state of the art technologies? Are you looking for an ambitious opportunity to test and grow your skills? Here is an opportunity…, , Working with one of our top financial clients, this role calls for a Database Engineer (Python/SQL/VBA) who will be working on a Trade Surveillance Project that will leverage the bank's Data Lake for vendor applications to create new data feeds utilizing Kafka and Nifi and Spark technology. The ideal candidate will be 50% production support as well as 50% coding (coding using Python and SQL): application is supporting VBA/ Macros. The role is more on the support side.The individual will be working with GWRT Compliance Technology group ensures ongoing compliance and optimization of trade platforms on a global scale., , Desired Skill-Set, 10+ years programming experience with Python, VBA Macros experience, Strong communication skills, , BeachHead is an equal opportunity agency and employer. We advocate for you and welcome anyone regardless of race, color, religion, national origin, sex, physical or mental disability, or age., , Privacy Policy","BeachHead is a premier and specialized consultancy and staffing firm focused on the Canadian Finance marketplace. We specialize in providing the highest quality of service for both our clients and professional Financial Candidates. Our unique business model supports a direct relationship with senior hiring business executives and stakeholders.

The BeachHead system is designed to capture intimate knowledge of both the client opportunity and qualified candidates, ensuring that each client/candidate is properly and competitively positioned in the marketplace."
